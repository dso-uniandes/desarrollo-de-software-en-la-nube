# üèÄ ANB - Cloud Project

Este proyecto implementa una API REST con **FastAPI** que permite subir archivos a **AWS S3 Bucket**, autenticarse mediante JWT y manejar una base de datos PostgreSQL

## üë• Integrantes del Equipo

| Nombre | Correo Uniandes |
|--------|-----------------|
| Jonatan Hernandez Rubio | je.hernandezr@uniandes.edu.co |
| Fernando Parra Villarreal | f.parrav@uniandes.edu.co |
| Daniel Serna Osorio | d.sernao@uniandes.edu.co |
| Harold Virg√ºez Engativa | h.virgueze@uniandes.edu.co |

---

## üö¶ Inicio R√°pido

### Para ejecutar la aplicaci√≥n:
```bash
# Opci√≥n 1: Docker Compose (Recomendado)
docker compose up -d
# Acceder: http://localhost/docs

# Opci√≥n 2: Desarrollo Local
# Ver secci√≥n "Ejecuci√≥n en Desarrollo Local"
```

### Para ejecutar tests:
```bash
# Tests unitarios (pytest)
ENV_STATE=test TEST_DATABASE_URL="postgresql+asyncpg://postgres:password@localhost:5432/test_db" python -m pytest storeapi/tests/ -v

# Tests de integraci√≥n (Newman)
newman run collections/Cloud-ANB.postman_collection.json --environment collections/postman_environment.json
```

---

## üìò Documentaci√≥n del Proyecto

Dentro del repositorio existe una carpeta `/docs/Entrega_1` que contiene toda la documentaci√≥n t√©cnica de la primera entrega, incluyendo:

- **Modelo de datos (ERD):** `data_model.md`
- **Diagrama de componentes de la arquitectura:** `component_diagram.md`
- **Flujo de procesamiento de videos:** `process_flow.md`
- **Gu√≠a de despliegue e infraestructura:** `deployment.md`
- **Colecciones de Postman:** `/collections/`

```
üìÇ ANB-back/
‚îú‚îÄ‚îÄ üìÇ capacity-planning/
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ postman/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ collection.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ report.html
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ report_20.html
‚îÇ   ‚îî‚îÄ‚îÄ plan_de_capacidad.md
‚îú‚îÄ‚îÄ üìÇ collections/
‚îÇ   ‚îú‚îÄ‚îÄ Cloud-ANB.postman_collection.json
‚îÇ   ‚îî‚îÄ‚îÄ postman_environment.json
‚îî‚îÄ‚îÄ üìÇ docs/
    ‚îî‚îÄ‚îÄ üìÇ Entrega_1/
        ‚îú‚îÄ‚îÄ component_diagram.md
        ‚îú‚îÄ‚îÄ data_model.md
        ‚îú‚îÄ‚îÄ deployment.md
        ‚îî‚îÄ‚îÄ process_flow.md
```

### üé• Video de Sustentaci√≥n

El video de sustentaci√≥n de la Entrega No. 1 se encuentra disponible en:
- **Documento de sustentaci√≥n:** `/sustentacion/Entrega_1/sustentacion.md`

---

## üöÄ Caracter√≠sticas principales

* Upload de archivos directamente a **AWS Cloud Storage**
* Soporte para entornos **test**, **dev** y **prod**
* Configuraci√≥n basada en **Pydantic Settings** y **dotenv (.env)**
* Conexi√≥n a base de datos **PostgreSQL** v√≠a **SQLAlchemy ORM**
* Tests autom√°ticos con `pytest` y `pytest-asyncio`

---

## ‚öôÔ∏è Requisitos previos

* **Python 3.13**
* **PostgreSQL** (para entorno de desarrollo)
* **Docker Desktop**
* **Cuenta en AWS** con credenciales v√°lidas
* **Acceso al bucket creado en AWS S3**

---

## üê≥ Configuraci√≥n de PostgreSQL con Docker

### Levantar PostgreSQL con Docker
Ejecuta el siguiente comando para levantar PostgreSQL:

```bash
docker run --name postgres-anb -e POSTGRES_PASSWORD=password -e POSTGRES_DB=dev_db -p 5432:5432 -d postgres:15
```

### Verificar que PostgreSQL est√© corriendo
```bash
docker ps
```

Deber√≠as ver el contenedor `postgres-anb` corriendo en el puerto 5432.

---

## üß© Configuraci√≥n del entorno

Crea un archivo llamado `.env` en la ra√≠z del proyecto con el siguiente contenido:

```dotenv
# Estado del entorno (dev, test, prod)
ENV_STATE=dev

# Base de datos PostgreSQL local (Docker)
DEV_DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/dev_db

# Base de datos de test
TEST_DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/test_db

# Base de datos de prod 
PROD_DATABASE_URL=anb-database.csxqmc4ywsa4.us-east-1.rds.amazonaws.com

# Credenciales de AWS S3
DEV_AWS_BUCKET_NAME=anb-s3-bucket
DEV_AWS_REGION=us-east-1
DEV_AWS_ACCESS_KEY_ID=tu_access_key
DEV_AWS_SECRET_ACCESS_KEY=tu_secret_key

# Kafka (Message Broker)
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_GROUP_ID=video_tasks_group

# Redis (Cach√© - opcional)
REDIS_URL=redis://localhost:6379
RANKING_CACHE_TTL=300

# Almacenamiento local de videos
UPLOADED_FOLDER=videos/uploaded
PROCESSED_FOLDER=videos/processed

# Configuraci√≥n del servidor
APP_HOST=0.0.0.0
APP_PORT=8000
```

---

## üß™ Tests Automatizados (pytest)

### Requisitos
- PostgreSQL corriendo (contenedor Docker standalone)
- Python 3.13 con dependencias instaladas

### 1. Levantar PostgreSQL para Tests
```bash
# Levantar PostgreSQL standalone (si no est√° corriendo)
docker run --name postgres-anb -e POSTGRES_PASSWORD=password -e POSTGRES_DB=dev_db -p 5432:5432 -d postgres:15

# Verificar que est√© corriendo
docker ps
```

### 2. Ejecutar Tests con pytest

#### Tests b√°sicos
```bash
# Todos los tests (PowerShell)
$env:ENV_STATE="test"; $env:TEST_DATABASE_URL="postgresql+asyncpg://postgres:password@localhost:5432/test_db"; python -m pytest storeapi/tests/ -v

# Tests b√°sicos (Bash/zsh)
ENV_STATE=test TEST_DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/test_db python -m pytest storeapi/tests/ -v
```

#### Tests con salida detallada
```bash
# PowerShell
$env:ENV_STATE="test"; $env:TEST_DATABASE_URL="postgresql+asyncpg://postgres:password@localhost:5432/test_db"; python -m pytest storeapi/tests/ -v --tb=short

# Bash/zsh
ENV_STATE=test TEST_DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/test_db python -m pytest storeapi/tests/ -v --tb=short
```

#### Tests espec√≠ficos
```bash
# Test de un m√≥dulo espec√≠fico (PowerShell)
$env:ENV_STATE="test"; $env:TEST_DATABASE_URL="postgresql+asyncpg://postgres:password@localhost:5432/test_db"; python -m pytest storeapi/tests/routers/test_user.py -v

# Test de un m√≥dulo espec√≠fico (Bash/zsh)
ENV_STATE=test TEST_DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/test_db python -m pytest storeapi/tests/routers/test_user.py -v

# Test espec√≠fico por nombre
ENV_STATE=test TEST_DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/test_db python -m pytest storeapi/tests/routers/test_user.py::test_create_user -v
```

### ‚ÑπÔ∏è Caracter√≠sticas de los Tests
- ‚úÖ **Base de datos separada**: Usa `test_db` (aislada de desarrollo)
- ‚úÖ **Rollback autom√°tico**: Los datos se limpian despu√©s de cada test
- ‚úÖ **Tests as√≠ncronos**: Utilizan `pytest-asyncio`
- ‚úÖ **Cobertura completa**: Autenticaci√≥n, usuarios, videos, votos, ranking

---

## üê≥ Ejecuci√≥n con Docker Compose (Recomendado)

### 1. Configurar archivo .env
Aseg√∫rate de tener un archivo `.env` en la ra√≠z con la siguiente configuraci√≥n m√≠nima:

```dotenv
# Estado del entorno
ENV_STATE=dev

# AWS S3 (usar credenciales locales para desarrollo)
DEV_AWS_BUCKET_NAME=anb-local-bucket
DEV_AWS_REGION=us-east-1
DEV_AWS_ACCESS_KEY_ID=test_key
DEV_AWS_SECRET_ACCESS_KEY=test_secret

# Kafka (no es necesario configurar, Docker Compose lo maneja)
# DEV_DATABASE_URL se configura autom√°ticamente en docker-compose.yml
```

### 2. Levantar todos los servicios

```bash
# Levantar toda la infraestructura
docker compose up -d

# Ver logs en tiempo real (opcional)
docker compose logs -f

# Verificar estado de servicios
docker compose ps
```

**Servicios levantados:**
- üóÑÔ∏è **PostgreSQL** (puerto 5432)
- üåê **StoreAPI** (expuesto internamente en puerto 8000)
- üîÑ **Nginx** (puerto 80) - Proxy reverso
- üì® **Kafka** (puerto 9092) - Message broker
- ‚öôÔ∏è **Worker** - Procesamiento de videos con FFmpeg
- üíæ **Redis** (puerto 6379) - Cach√©

### 3. Verificar que los servicios est√©n listos

```bash
# Verificar todos los contenedores
docker compose ps

# Salida esperada:
# NAME          STATUS          PORTS
# database      Up (healthy)    0.0.0.0:5432->5432/tcp
# storeapi      Up              8000/tcp
# proxy         Up              0.0.0.0:80->80/tcp
# kafka         Up (healthy)    0.0.0.0:9092->9092/tcp
# worker        Up              
# redis         Up              0.0.0.0:6379->6379/tcp

# Ver logs de un servicio espec√≠fico
docker compose logs storeapi --tail 50
docker compose logs worker --tail 50
```

### 4. Acceder a la API

üåê **API**: [http://localhost/docs](http://localhost/docs)  
üîó **Endpoints**:
- `http://localhost/api/auth/login`
- `http://localhost/api/videos/upload`
- `http://localhost/api/ranking`

### 5. Ejecutar Tests con Newman (Docker Compose)

**Prerequisitos:**
```bash
# Instalar Newman si no lo tienes
npm install -g newman

# Verificar instalaci√≥n
newman --version
```

**Ejecutar tests:**
```bash
# Ejecutar toda la colecci√≥n de tests
newman run collections/Cloud-ANB.postman_collection.json --environment collections/postman_environment.json
```

**Resultados esperados:**
Al ejecutar los tests exitosamente, deber√≠as ver:
- **25 requests ejecutados** ‚úÖ
- **22 test scripts ejecutados** ‚úÖ  
- **26 pre-request scripts ejecutados** ‚úÖ
- **61 de 61 assertions pasaron** ‚úÖ (100% de √©xito)

**Nota importante:**
- Los tests incluyen un delay de 10 segundos para esperar que los videos se procesen
- El worker de Kafka debe estar corriendo para que los videos se procesen correctamente
- Los tests de votaci√≥n requieren que los videos est√©n en estado "processed"

---

## ‚ñ∂Ô∏è Ejecuci√≥n en Desarrollo Local (Sin Docker Compose)

Para desarrollo local con m√°s control y debugging.

### 1. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 2. Levantar servicios individuales

#### PostgreSQL
```bash
docker run --name postgres-anb -e POSTGRES_PASSWORD=password -e POSTGRES_DB=dev_db -p 5432:5432 -d postgres:15
```

#### Kafka (opcional, si necesitas procesamiento de videos)
```bash
docker run --name kafka-dev -p 9092:9092 -e KAFKA_ENABLE_KRAFT=yes -e KAFKA_CFG_NODE_ID=1 -e KAFKA_CFG_PROCESS_ROLES=broker,controller -e KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@localhost:9093 -e KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093 -e KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 -e KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER bitnamilegacy/kafka:4.0.0-debian-12-r10
```

### 3. Configurar variables de entorno

**PowerShell:**
```powershell
$env:ENV_STATE="dev"
$env:DEV_DATABASE_URL="postgresql+asyncpg://postgres:password@localhost:5432/dev_db"
$env:DEV_AWS_ACCESS_KEY_ID="test_key"
$env:DEV_AWS_SECRET_ACCESS_KEY="test_secret"
$env:DEV_AWS_BUCKET_NAME="test_bucket"
$env:DEV_AWS_REGION="us-east-1"
$env:KAFKA_BOOTSTRAP_SERVERS="localhost:9092"
```

**Bash/zsh:**
```bash
export ENV_STATE=dev
export DEV_DATABASE_URL="postgresql+asyncpg://postgres:password@localhost:5432/dev_db"
export DEV_AWS_ACCESS_KEY_ID="test_key"
export DEV_AWS_SECRET_ACCESS_KEY="test_secret"
export DEV_AWS_BUCKET_NAME="test_bucket"
export DEV_AWS_REGION="us-east-1"
export KAFKA_BOOTSTRAP_SERVERS="localhost:9092"
```

### 4. Ejecutar el API

**PowerShell:**
```powershell
$env:ENV_STATE="dev"; $env:DEV_DATABASE_URL="postgresql+asyncpg://postgres:password@localhost:5432/dev_db"; python -m uvicorn storeapi.main:app --reload --host 0.0.0.0 --port 8000
```

**Bash/zsh:**
```bash
ENV_STATE=dev DEV_DATABASE_URL="postgresql+asyncpg://postgres:password@localhost:5432/dev_db" python -m uvicorn storeapi.main:app --reload --host 0.0.0.0 --port 8000
```

### 5. Ejecutar el Worker (opcional, en otra terminal)

**PowerShell:**
```powershell
$env:ENV_STATE="dev"; $env:DEV_DATABASE_URL="postgresql+asyncpg://postgres:password@localhost:5432/dev_db"; $env:KAFKA_BOOTSTRAP_SERVERS="localhost:9092"; python -m message_broker.worker
```

**Bash/zsh:**
```bash
ENV_STATE=dev DEV_DATABASE_URL="postgresql+asyncpg://postgres:password@localhost:5432/dev_db" KAFKA_BOOTSTRAP_SERVERS="localhost:9092" python -m message_broker.worker
```

### 6. Acceder a la documentaci√≥n

üåê **Swagger UI**: [http://localhost:8000/docs](http://localhost:8000/docs)

**Nota importante**: 
- En desarrollo local, el API corre directamente en el **puerto 8000** (sin proxy)
- Con Docker Compose, se accede a trav√©s de Nginx en el **puerto 80**: [http://localhost/docs](http://localhost/docs)
- El servidor crear√° autom√°ticamente las tablas en PostgreSQL al iniciar

---

## üìÅ Estructura del Proyecto

```
desarrollo-de-software-en-la-nube/
‚îú‚îÄ‚îÄ üìÇ storeapi/                         # API REST - FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ main.py                          # Punto de entrada de la aplicaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ database.py                      # Configuraci√≥n de SQLAlchemy
‚îÇ   ‚îú‚îÄ‚îÄ security.py                      # Autenticaci√≥n JWT
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ routers/                      # Endpoints de la API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ user.py                      # Auth (login, signup)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ video.py                     # Upload, stream, list, delete
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vote.py                      # Sistema de votaci√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ranking.py                   # Rankings por ciudad
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ models/                       # Modelos SQLAlchemy (ORM)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ user.py                      # Tabla users
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ video.py                     # Tabla videos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vote.py                      # Tabla votes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ranking.py                   # Vista ranking
‚îÇ   ‚îî‚îÄ‚îÄ üìÇ tests/                        # Tests unitarios (pytest)
‚îÇ       ‚îú‚îÄ‚îÄ conftest.py                  # Fixtures
‚îÇ       ‚îú‚îÄ‚îÄ test_security.py             # Tests de JWT
‚îÇ       ‚îî‚îÄ‚îÄ routers/                     # Tests de endpoints
‚îÇ
‚îú‚îÄ‚îÄ üìÇ message_broker/                   # Sistema de cola de mensajes
‚îÇ   ‚îú‚îÄ‚îÄ client.py                        # Cliente Kafka producer
‚îÇ   ‚îú‚îÄ‚îÄ tasks_dispatcher.py              # Encolador de tareas
‚îÇ   ‚îî‚îÄ‚îÄ worker.py                        # Consumer - Procesa videos
‚îÇ
‚îú‚îÄ‚îÄ üìÇ utils/                            # Utilidades compartidas
‚îÇ   ‚îú‚îÄ‚îÄ config.py                        # Configuraci√≥n (Pydantic)
‚îÇ   ‚îú‚îÄ‚îÄ cache.py                         # Cliente Redis
‚îÇ   ‚îú‚îÄ‚îÄ logging_conf.py                  # Logging estructurado
‚îÇ   ‚îú‚îÄ‚îÄ ffmpeg.py                        # Procesamiento con FFmpeg
‚îÇ   ‚îî‚îÄ‚îÄ üìÇ s3/
‚îÇ       ‚îú‚îÄ‚îÄ s3.py                        # Cliente AWS S3
‚îÇ       ‚îî‚îÄ‚îÄ s3_local.py                  # Storage local (desarrollo)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ capacity-planning/                # Plan de an√°lisis de capacidad
‚îÇ   ‚îú‚îÄ‚îÄ Makefile                         # Comandos para pruebas
‚îÇ   ‚îú‚îÄ‚îÄ plan_de_capacidad.md             # Documento del plan
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ postman/                      # Tests de integraci√≥n (Newman)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ collection.json              # Colecci√≥n para Newman CLI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ environment.json             # Variables de entorno
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ report.html                  # Reporte HTML generado
‚îÇ   ‚îî‚îÄ‚îÄ üìÇ results/                      # Resultados de pruebas (crear)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ docs/                             # Documentaci√≥n t√©cnica
‚îÇ   ‚îî‚îÄ‚îÄ üìÇ Entrega_1/
‚îÇ       ‚îú‚îÄ‚îÄ data_model.md                # Modelo de datos (ERD)
‚îÇ       ‚îú‚îÄ‚îÄ component_diagram.md         # Arquitectura
‚îÇ       ‚îú‚îÄ‚îÄ process_flow.md              # Flujo de procesamiento
‚îÇ       ‚îî‚îÄ‚îÄ deployment.md                # Gu√≠a de despliegue
‚îÇ
‚îú‚îÄ‚îÄ üìÇ sustentacion/                     # Videos de sustentaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ üìÇ Entrega_1/
‚îÇ       ‚îî‚îÄ‚îÄ sustentacion.md              # Documento con enlace al video
‚îÇ
‚îú‚îÄ‚îÄ üìÇ collections/                      # Colecciones Postman (UI)
‚îÇ   ‚îú‚îÄ‚îÄ Cloud-ANB.postman_collection.json
‚îÇ   ‚îî‚îÄ‚îÄ postman_environment.json
‚îÇ
‚îú‚îÄ‚îÄ üìÇ videos/                           # Almacenamiento local de videos
‚îÇ   ‚îú‚îÄ‚îÄ uploaded/                        # Videos subidos (originales)
‚îÇ   ‚îî‚îÄ‚îÄ processed/                       # Videos procesados (con branding)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ img/
‚îÇ   ‚îî‚îÄ‚îÄ logo_nba.png                     # Logo para intro/outro de videos
‚îÇ
‚îú‚îÄ‚îÄ üê≥ docker-compose.yml                # Orquestaci√≥n de servicios
‚îú‚îÄ‚îÄ üê≥ api.Dockerfile                    # Imagen del API (FastAPI)
‚îú‚îÄ‚îÄ üê≥ worker.Dockerfile                 # Imagen del worker (FFmpeg)
‚îú‚îÄ‚îÄ üê≥ ffmpegpy.Dockerfile               # Base con FFmpeg + Python
‚îú‚îÄ‚îÄ ÔøΩ nginx.conf                        # Configuraci√≥n Nginx (proxy)
‚îú‚îÄ‚îÄ ÔøΩ Makefile                          # Comandos Docker Compose (ra√≠z)
‚îú‚îÄ‚îÄ ÔøΩ monitor.sh                        # Script de monitoreo de recursos
‚îú‚îÄ‚îÄ ÔøΩ requirements.txt                  # Dependencias Python
‚îú‚îÄ‚îÄ ÔøΩ .env                              # Variables de entorno (crear)
‚îî‚îÄ‚îÄ üìñ README.md                         # Este archivo
```

### Descripci√≥n de Servicios (Docker Compose)

| Servicio | Puerto | Descripci√≥n | Tecnolog√≠a |
|----------|--------|-------------|------------|
| **nginx** | 80 | Proxy reverso y balanceador | Nginx |
| **storeapi** | 8000 (interno) | API REST principal | FastAPI + Python 3.11 |
| **worker** | - | Procesador as√≠ncrono de videos | Python 3.11 + FFmpeg |
| **db** | 5432 | Base de datos relacional | PostgreSQL 15 |
| **kafka** | 9092 | Message broker para tareas | Apache Kafka (KRaft) |
| **redis** | 6379 | Cach√© para ranking | Redis 7 |

### Flujo de Datos

1. **Upload**: Cliente ‚Üí Nginx (80) ‚Üí StoreAPI ‚Üí S3/Local + Kafka
2. **Procesamiento**: Kafka ‚Üí Worker ‚Üí FFmpeg ‚Üí S3/Local ‚Üí DB (update status)
3. **Consultas**: Cliente ‚Üí Nginx ‚Üí StoreAPI ‚Üí Redis (cache) / DB ‚Üí Response

---
