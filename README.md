# ğŸ€ ANB - Cloud Project

Este proyecto implementa una API REST con **FastAPI** que permite subir archivos a **AWS S3 Bucket**, autenticarse mediante JWT y manejar una base de datos PostgreSQL

## ğŸ‘¥ Integrantes del Equipo 8

| Nombre | Correo Uniandes |
|--------|-----------------|
| Jonatan Hernandez Rubio | je.hernandezr@uniandes.edu.co |
| Fernando Parra Villarreal | f.parrav@uniandes.edu.co |
| Daniel Serna Osorio | d.sernao@uniandes.edu.co |
| Harold VirgÃ¼ez Engativa | h.virgueze@uniandes.edu.co |

## Entregas

### ğŸ“‹ Entrega 1 - Desarrollo Local
- [DocumentaciÃ³n tÃ©cnica](./docs/Entrega_1/) - Arquitectura, modelo de datos y despliegue
- [Video de sustentaciÃ³n](./sustentacion/Entrega_1/sustentacion.md)
- [Plan de Capacidad](./capacity-planning/plan_de_pruebas.md) 

### â˜ï¸ Entrega 2 - MigraciÃ³n AWS
- [DocumentaciÃ³n tÃ©cnica](./docs/Entrega_2/) - Arquitectura AWS
- [AnÃ¡lisis de capacidad](./capacity-planning/Entrega_2/pruebas_de_carga_entrega2.md) - Pruebas de estrÃ©s
- [Reporte SonarQube](./docs/Entrega_2/SonarQube_analysis/) - AnÃ¡lisis de calidad
- [Video de sustentaciÃ³n](./sustentacion/Entrega_1/sustentacion.md)

### â˜ï¸ Entrega 3 - Load balancer/ auto scaling
---
- [DocumentaciÃ³n tÃ©cnica](./docs/Entrega_3/) - Arquitectura AWS
- [AnÃ¡lisis de capacidad](./capacity-planning/Entrega_3/pruebas_de_carga_entrega3.md) - Pruebas de estrÃ©s
- [Reporte SonarQube](./docs/Entrega_3/SonarQube_analysis/) - AnÃ¡lisis de calidad
- [Video de sustentaciÃ³n](./sustentacion/Entrega_1/sustentacion.md)
- [Video de sustentaciÃ³n 2](https://uniandes-my.sharepoint.com/:v:/g/personal/f_parrav_uniandes_edu_co/EUEUS4CKdkpOmMDBeM1LfdABDajq83a5hs1O8ri2SFNadA?e=KWPA1f)

### â˜ï¸ Entrega 4 - Escalabilidad en la Capa Worker
---
- [DocumentaciÃ³n tÃ©cnica](./docs/Entrega_4/) - Arquitectura AWS
- [AnÃ¡lisis de capacidad](./capacity-planning/Entrega_4/pruebas_de_carga_entrega4.md) - Pruebas de estrÃ©s
- [Video Sustentacion](https://uniandes-my.sharepoint.com/:v:/g/personal/d_sernao_uniandes_edu_co/IQDnhMwaJqqEQI-PzO-blM7KAdGrP7bUP5jcnuss5W7x3vU?nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJPbmVEcml2ZUZvckJ1c2luZXNzIiwicmVmZXJyYWxBcHBQbGF0Zm9ybSI6IldlYiIsInJlZmVycmFsTW9kZSI6InZpZXciLCJyZWZlcnJhbFZpZXciOiJNeUZpbGVzTGlua0NvcHkifX0&e=YGMlPa)

### â˜ï¸ Entrega 5 - PAAS Capa Web y Worker
---
- [DocumentaciÃ³n tÃ©cnica](./docs/Entrega_5/) - Arquitectura AWS 
- [AnÃ¡lisis de capacidad](./capacity-planning/pruebas_de_carga_entrega5.md) - Pruebas de estrÃ©s
- [Video Sustentacion](https://uniandes-my.sharepoint.com/:v:/g/personal/d_sernao_uniandes_edu_co/IQDnhMwaJqqEQI-PzO-blM7KAdGrP7bUP5jcnuss5W7x3vU?nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJPbmVEcml2ZUZvckJ1c2luZXNzIiwicmVmZXJyYWxBcHBQbGF0Zm9ybSI6IldlYiIsInJlZmVycmFsTW9kZSI6InZpZXciLCJyZWZlcnJhbFZpZXciOiJNeUZpbGVzTGlua0NvcHkifX0&e=YGMlPa)

---

## ğŸš¦ Inicio RÃ¡pido

### Para ejecutar la aplicaciÃ³n:
```bash
# OpciÃ³n 1: Docker Compose (Recomendado)
docker compose up -d
# Acceder: http://localhost/docs

# OpciÃ³n 2: Desarrollo Local
# Ver secciÃ³n "EjecuciÃ³n en Desarrollo Local"
```

### Para ejecutar tests:
```bash
# Tests unitarios (pytest)
ENV_STATE=test TEST_DATABASE_URL="postgresql+asyncpg://postgres:password@localhost:5432/test_db" python -m pytest storeapi/tests/ -v

# Tests de integraciÃ³n (Newman)
newman run collections/Cloud-ANB.postman_collection.json --environment collections/postman_environment.json
```

---

## ğŸš€ CaracterÃ­sticas principales

* Upload de archivos directamente a **AWS Cloud Storage**
* Soporte para entornos **test**, **dev** y **prod**
* ConfiguraciÃ³n basada en **Pydantic Settings** y **dotenv (.env)**
* ConexiÃ³n a base de datos **PostgreSQL** vÃ­a **SQLAlchemy ORM**
* Tests automÃ¡ticos con `pytest` y `pytest-asyncio`

---

## âš™ï¸ Requisitos previos

* **Python 3.13**
* **PostgreSQL** (para entorno de desarrollo)
* **Docker Desktop**
* **Cuenta en AWS** con credenciales vÃ¡lidas
* **Acceso al bucket creado en AWS S3**

---

## ğŸ³ ConfiguraciÃ³n de PostgreSQL con Docker

### Levantar PostgreSQL con Docker
Ejecuta el siguiente comando para levantar PostgreSQL:

```bash
docker run --name postgres-anb -e POSTGRES_PASSWORD=password -e POSTGRES_DB=dev_db -p 5432:5432 -d postgres:15
```

### Verificar que PostgreSQL estÃ© corriendo
```bash
docker ps
```

DeberÃ­as ver el contenedor `postgres-anb` corriendo en el puerto 5432.

---

## ğŸ§© ConfiguraciÃ³n del entorno

Crea un archivo llamado `.env` en la raÃ­z del proyecto con el siguiente contenido:

```dotenv
# Estado del entorno (dev, test, prod)
ENV_STATE=dev

# Base de datos PostgreSQL local (Docker)
DEV_DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/dev_db

# Base de datos de test
TEST_DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/test_db

# Base de datos de prod 
PROD_DATABASE_URL=anb-database.csxqmc4ywsa4.us-east-1.rds.amazonaws.com

# Credenciales de AWS S3
DEV_AWS_BUCKET_NAME=anb-s3-bucket
DEV_AWS_REGION=us-east-1
DEV_AWS_ACCESS_KEY_ID=tu_access_key
DEV_AWS_SECRET_ACCESS_KEY=tu_secret_key

# Kafka (Message Broker)
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_GROUP_ID=video_tasks_group

# Redis (CachÃ© - opcional)
REDIS_URL=redis://localhost:6379
RANKING_CACHE_TTL=300

# Almacenamiento local de videos
UPLOADED_FOLDER=videos/uploaded
PROCESSED_FOLDER=videos/processed

# ConfiguraciÃ³n del servidor
APP_HOST=0.0.0.0
APP_PORT=8000
```

---

## ğŸ§ª Tests Automatizados (pytest)

### Requisitos
- PostgreSQL corriendo (contenedor Docker standalone)
- Python 3.13 con dependencias instaladas

### 1. Levantar PostgreSQL para Tests
```bash
# Levantar PostgreSQL standalone (si no estÃ¡ corriendo)
docker run --name postgres-anb -e POSTGRES_PASSWORD=password -e POSTGRES_DB=dev_db -p 5432:5432 -d postgres:15

# Verificar que estÃ© corriendo
docker ps
```

### 2. Ejecutar Tests con pytest

#### Tests bÃ¡sicos
```bash
# Todos los tests (PowerShell)
$env:ENV_STATE="test"; $env:TEST_DATABASE_URL="postgresql+asyncpg://postgres:password@localhost:5432/test_db"; python -m pytest storeapi/tests/ -v

# Tests bÃ¡sicos (Bash/zsh)
ENV_STATE=test TEST_DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/test_db python -m pytest storeapi/tests/ -v
```

#### Tests con salida detallada
```bash
# PowerShell
$env:ENV_STATE="test"; $env:TEST_DATABASE_URL="postgresql+asyncpg://postgres:password@localhost:5432/test_db"; python -m pytest storeapi/tests/ -v --tb=short

# Bash/zsh
ENV_STATE=test TEST_DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/test_db python -m pytest storeapi/tests/ -v --tb=short
```

#### Tests especÃ­ficos
```bash
# Test de un mÃ³dulo especÃ­fico (PowerShell)
$env:ENV_STATE="test"; $env:TEST_DATABASE_URL="postgresql+asyncpg://postgres:password@localhost:5432/test_db"; python -m pytest storeapi/tests/routers/test_user.py -v

# Test de un mÃ³dulo especÃ­fico (Bash/zsh)
ENV_STATE=test TEST_DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/test_db python -m pytest storeapi/tests/routers/test_user.py -v

# Test especÃ­fico por nombre
ENV_STATE=test TEST_DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/test_db python -m pytest storeapi/tests/routers/test_user.py::test_create_user -v
```

### â„¹ï¸ CaracterÃ­sticas de los Tests
- âœ… **Base de datos separada**: Usa `test_db` (aislada de desarrollo)
- âœ… **Rollback automÃ¡tico**: Los datos se limpian despuÃ©s de cada test
- âœ… **Tests asÃ­ncronos**: Utilizan `pytest-asyncio`
- âœ… **Cobertura completa**: AutenticaciÃ³n, usuarios, videos, votos, ranking

---

## ğŸ³ EjecuciÃ³n con Docker Compose (Recomendado)

### 1. Configurar archivo .env
AsegÃºrate de tener un archivo `.env` en la raÃ­z con la siguiente configuraciÃ³n mÃ­nima:

```dotenv
# Estado del entorno
ENV_STATE=dev

# AWS S3 (usar credenciales locales para desarrollo)
DEV_AWS_BUCKET_NAME=anb-local-bucket
DEV_AWS_REGION=us-east-1
DEV_AWS_ACCESS_KEY_ID=test_key
DEV_AWS_SECRET_ACCESS_KEY=test_secret

# Kafka (no es necesario configurar, Docker Compose lo maneja)
# DEV_DATABASE_URL se configura automÃ¡ticamente en docker-compose.yml
```

### 2. Levantar todos los servicios

```bash
# Levantar toda la infraestructura
docker compose up -d

# Ver logs en tiempo real (opcional)
docker compose logs -f

# Verificar estado de servicios
docker compose ps
```

**Servicios levantados:**
- ğŸ—„ï¸ **PostgreSQL** (puerto 5432)
- ğŸŒ **StoreAPI** (expuesto internamente en puerto 8000)
- ğŸ”„ **Nginx** (puerto 80) - Proxy reverso
- ğŸ“¨ **Kafka** (puerto 9092) - Message broker
- âš™ï¸ **Worker** - Procesamiento de videos con FFmpeg
- ğŸ’¾ **Redis** (puerto 6379) - CachÃ©

### 3. Verificar que los servicios estÃ©n listos

```bash
# Verificar todos los contenedores
docker compose ps

# Salida esperada:
# NAME          STATUS          PORTS
# database      Up (healthy)    0.0.0.0:5432->5432/tcp
# storeapi      Up              8000/tcp
# proxy         Up              0.0.0.0:80->80/tcp
# kafka         Up (healthy)    0.0.0.0:9092->9092/tcp
# worker        Up              
# redis         Up              0.0.0.0:6379->6379/tcp

# Ver logs de un servicio especÃ­fico
docker compose logs storeapi --tail 50
docker compose logs worker --tail 50
```

### 4. Acceder a la API

ğŸŒ **API**: [http://localhost/docs](http://localhost/docs)  
ğŸ”— **Endpoints**:
- `http://localhost/api/auth/login`
- `http://localhost/api/videos/upload`
- `http://localhost/api/ranking`

### 5. Ejecutar Tests con Newman (Docker Compose)

**Prerequisitos:**
```bash
# Instalar Newman si no lo tienes
npm install -g newman

# Verificar instalaciÃ³n
newman --version
```

**Ejecutar tests:**
```bash
# Ejecutar toda la colecciÃ³n de tests
newman run collections/Cloud-ANB.postman_collection.json --environment collections/postman_environment.json
```

**Resultados esperados:**
Al ejecutar los tests exitosamente, deberÃ­as ver:
- **25 requests ejecutados** âœ…
- **22 test scripts ejecutados** âœ…  
- **26 pre-request scripts ejecutados** âœ…
- **61 de 61 assertions pasaron** âœ… (100% de Ã©xito)

**Nota importante:**
- Los tests incluyen un delay de 10 segundos para esperar que los videos se procesen
- El worker de Kafka debe estar corriendo para que los videos se procesen correctamente
- Los tests de votaciÃ³n requieren que los videos estÃ©n en estado "processed"

---

## â–¶ï¸ EjecuciÃ³n en Desarrollo Local (Sin Docker Compose)

Para desarrollo local con mÃ¡s control y debugging.

### 1. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 2. Levantar servicios individuales

#### PostgreSQL
```bash
docker run --name postgres-anb -e POSTGRES_PASSWORD=password -e POSTGRES_DB=dev_db -p 5432:5432 -d postgres:15
```

#### Kafka (opcional, si necesitas procesamiento de videos)
```bash
docker run --name kafka-dev -p 9092:9092 -e KAFKA_ENABLE_KRAFT=yes -e KAFKA_CFG_NODE_ID=1 -e KAFKA_CFG_PROCESS_ROLES=broker,controller -e KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@localhost:9093 -e KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093 -e KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 -e KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER bitnamilegacy/kafka:4.0.0-debian-12-r10
```

### 3. Configurar variables de entorno

**PowerShell:**
```powershell
$env:ENV_STATE="dev"
$env:DEV_DATABASE_URL="postgresql+asyncpg://postgres:password@localhost:5432/dev_db"
$env:DEV_AWS_ACCESS_KEY_ID="test_key"
$env:DEV_AWS_SECRET_ACCESS_KEY="test_secret"
$env:DEV_AWS_BUCKET_NAME="test_bucket"
$env:DEV_AWS_REGION="us-east-1"
$env:KAFKA_BOOTSTRAP_SERVERS="localhost:9092"
```

**Bash/zsh:**
```bash
export ENV_STATE=dev
export DEV_DATABASE_URL="postgresql+asyncpg://postgres:password@localhost:5432/dev_db"
export DEV_AWS_ACCESS_KEY_ID="test_key"
export DEV_AWS_SECRET_ACCESS_KEY="test_secret"
export DEV_AWS_BUCKET_NAME="test_bucket"
export DEV_AWS_REGION="us-east-1"
export KAFKA_BOOTSTRAP_SERVERS="localhost:9092"
```

### 4. Ejecutar el API

**PowerShell:**
```powershell
$env:ENV_STATE="dev"; $env:DEV_DATABASE_URL="postgresql+asyncpg://postgres:password@localhost:5432/dev_db"; python -m uvicorn storeapi.main:app --reload --host 0.0.0.0 --port 8000
```

**Bash/zsh:**
```bash
ENV_STATE=dev DEV_DATABASE_URL="postgresql+asyncpg://postgres:password@localhost:5432/dev_db" python -m uvicorn storeapi.main:app --reload --host 0.0.0.0 --port 8000
```

### 5. Ejecutar el Worker (opcional, en otra terminal)

**PowerShell:**
```powershell
$env:ENV_STATE="dev"; $env:DEV_DATABASE_URL="postgresql+asyncpg://postgres:password@localhost:5432/dev_db"; $env:KAFKA_BOOTSTRAP_SERVERS="localhost:9092"; python -m message_broker.worker
```

**Bash/zsh:**
```bash
ENV_STATE=dev DEV_DATABASE_URL="postgresql+asyncpg://postgres:password@localhost:5432/dev_db" KAFKA_BOOTSTRAP_SERVERS="localhost:9092" python -m message_broker.worker
```

### 6. Acceder a la documentaciÃ³n

ğŸŒ **Swagger UI**: [http://localhost:8000/docs](http://localhost:8000/docs)

**Nota importante**: 
- En desarrollo local, el API corre directamente en el **puerto 8000** (sin proxy)
- Con Docker Compose, se accede a travÃ©s de Nginx en el **puerto 80**: [http://localhost/docs](http://localhost/docs)
- El servidor crearÃ¡ automÃ¡ticamente las tablas en PostgreSQL al iniciar

---

## ğŸ“ Estructura del Proyecto

```
desarrollo-de-software-en-la-nube/
â”œâ”€â”€ ğŸ“‚ storeapi/                         # API REST - FastAPI
â”‚   â”œâ”€â”€ main.py                          # Punto de entrada de la aplicaciÃ³n
â”‚   â”œâ”€â”€ database.py                      # ConfiguraciÃ³n de SQLAlchemy
â”‚   â”œâ”€â”€ security.py                      # AutenticaciÃ³n JWT
â”‚   â”œâ”€â”€ ğŸ“‚ routers/                      # Endpoints de la API
â”‚   â”‚   â”œâ”€â”€ user.py                      # Auth (login, signup)
â”‚   â”‚   â”œâ”€â”€ video.py                     # Upload, stream, list, delete
â”‚   â”‚   â”œâ”€â”€ vote.py                      # Sistema de votaciÃ³n
â”‚   â”‚   â””â”€â”€ ranking.py                   # Rankings por ciudad
â”‚   â”œâ”€â”€ ğŸ“‚ models/                       # Modelos SQLAlchemy (ORM)
â”‚   â”‚   â”œâ”€â”€ user.py                      # Tabla users
â”‚   â”‚   â”œâ”€â”€ video.py                     # Tabla videos
â”‚   â”‚   â”œâ”€â”€ vote.py                      # Tabla votes
â”‚   â”‚   â””â”€â”€ ranking.py                   # Vista ranking
â”‚   â””â”€â”€ ğŸ“‚ tests/                        # Tests unitarios (pytest)
â”‚       â”œâ”€â”€ conftest.py                  # Fixtures
â”‚       â”œâ”€â”€ test_security.py             # Tests de JWT
â”‚       â””â”€â”€ routers/                     # Tests de endpoints
â”‚
â”œâ”€â”€ ğŸ“‚ message_broker/                   # Sistema de cola de mensajes
â”‚   â”œâ”€â”€ client.py                        # Cliente Kafka producer
â”‚   â”œâ”€â”€ tasks_dispatcher.py              # Encolador de tareas
â”‚   â””â”€â”€ worker.py                        # Consumer - Procesa videos
â”‚
â”œâ”€â”€ ğŸ“‚ utils/                            # Utilidades compartidas
â”‚   â”œâ”€â”€ config.py                        # ConfiguraciÃ³n (Pydantic)
â”‚   â”œâ”€â”€ cache.py                         # Cliente Redis
â”‚   â”œâ”€â”€ logging_conf.py                  # Logging estructurado
â”‚   â”œâ”€â”€ ffmpeg.py                        # Procesamiento con FFmpeg
â”‚   â””â”€â”€ ğŸ“‚ s3/
â”‚       â”œâ”€â”€ s3.py                        # Cliente AWS S3
â”‚       â””â”€â”€ s3_local.py                  # Storage local (desarrollo)
â”‚
â”œâ”€â”€ ğŸ“‚ capacity-planning/                # Plan de anÃ¡lisis de capacidad
â”‚   â”œâ”€â”€ Makefile                         # Comandos para pruebas
â”‚   â”œâ”€â”€ plan_de_pruebas.md               # Plan de pruebas Entrega 1
â”‚   â”œâ”€â”€ pruebas_de_carga_entrega5.md     # AnÃ¡lisis de capacidad Entrega 5
â”‚   â”œâ”€â”€ ğŸ“‚ Entrega_2/                     # Entrega 2
â”‚   â”‚   â”œâ”€â”€ pruebas_de_carga_entrega2.md # AnÃ¡lisis de capacidad
â”‚   â”‚   â”œâ”€â”€ resultados/                  # Resultados de pruebas
â”‚   â”‚   â””â”€â”€ resultados_entrega_2/        # AnÃ¡lisis de capacidad
â”‚   â”œâ”€â”€ ğŸ“‚ Entrega_3/                     # Entrega 3
â”‚   â”‚   â”œâ”€â”€ pruebas_de_carga_entrega3.md # AnÃ¡lisis de capacidad
â”‚   â”‚   â””â”€â”€ resultados_entrega_3/       # Resultados de pruebas
â”‚   â””â”€â”€ ğŸ“‚ Entrega_4/                     # Entrega 4
â”‚       â”œâ”€â”€ plan_de_pruebas.md           # Plan de pruebas
â”‚       â”œâ”€â”€ pruebas_de_carga_entrega4.md # AnÃ¡lisis de capacidad
â”‚       â””â”€â”€ postman/                      # Tests de integraciÃ³n (Newman)
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                             # DocumentaciÃ³n tÃ©cnica
â”‚   â”œâ”€â”€ ğŸ“‚ Entrega_1/
â”‚   â”‚   â”œâ”€â”€ data_model.md                # Modelo de datos (ERD)
â”‚   â”‚   â”œâ”€â”€ component_diagram.md         # Arquitectura
â”‚   â”‚   â”œâ”€â”€ process_flow.md              # Flujo de procesamiento
â”‚   â”‚   â””â”€â”€ deployment.md                # GuÃ­a de despliegue
â”‚   â”œâ”€â”€ ğŸ“‚ Entrega_2/
â”‚   â”‚   â”œâ”€â”€ component_diagram.md         # Arquitectura AWS
â”‚   â”‚   â”œâ”€â”€ data_model.md                # Modelo de datos actualizado
â”‚   â”‚   â”œâ”€â”€ validate_endpoints.md        # ValidaciÃ³n de endpoints
â”‚   â”‚   â””â”€â”€ ğŸ“‚ SonarQube_analysis/        # AnÃ¡lisis de calidad de cÃ³digo
â”‚   â”‚       â”œâ”€â”€ sonar_analysis.md        # Reporte de anÃ¡lisis
â”‚   â”‚       â””â”€â”€ sonar_issues_fixed.md    # Issues corregidos
â”‚   â”œâ”€â”€ ğŸ“‚ Entrega_3/
â”‚   â”‚   â”œâ”€â”€ component_diagram.md         # Arquitectura AWS
â”‚   â”‚   â”œâ”€â”€ data_model.md                # Modelo de datos
â”‚   â”‚   â”œâ”€â”€ process_flow.md              # Flujo de procesamiento
â”‚   â”‚   â””â”€â”€ ğŸ“‚ SonarQube_analysis/        # AnÃ¡lisis de calidad de cÃ³digo
â”‚   â””â”€â”€ ğŸ“‚ Entrega_4/
â”‚       â”œâ”€â”€ component_diagram.md         # Arquitectura AWS
â”‚       â”œâ”€â”€ data_model.md                # Modelo de datos
â”‚       â””â”€â”€ process_flow.md              # Flujo de procesamiento
â”‚
â”œâ”€â”€ ğŸ“‚ sustentacion/                     # Videos de sustentaciÃ³n
â”‚   â””â”€â”€ ğŸ“‚ Entrega_1/
â”‚       â””â”€â”€ sustentacion.md              # Documento con enlace al video
â”‚
â”œâ”€â”€ ğŸ“‚ collections/                      # Colecciones Postman (UI)
â”‚   â”œâ”€â”€ Cloud-ANB.postman_collection.json
â”‚   â””â”€â”€ postman_environment.json
â”‚
â”œâ”€â”€ ğŸ“‚ videos/                           # Almacenamiento local de videos
â”‚   â”œâ”€â”€ uploaded/                        # Videos subidos (originales)
â”‚   â””â”€â”€ processed/                       # Videos procesados (con branding)
â”‚
â”œâ”€â”€ ğŸ“‚ img/
â”‚   â””â”€â”€ logo_nba.png                     # Logo para intro/outro de videos
â”‚
â”œâ”€â”€ ğŸ³ docker-compose.yml                # OrquestaciÃ³n de servicios
â”œâ”€â”€ ğŸ³ api.Dockerfile                    # Imagen del API (FastAPI)
â”œâ”€â”€ ğŸ³ worker.Dockerfile                 # Imagen del worker (FFmpeg)
â”œâ”€â”€ ğŸ³ ffmpegpy.Dockerfile               # Base con FFmpeg + Python
â”œâ”€â”€ ï¿½ nginx.conf                        # ConfiguraciÃ³n Nginx (proxy)
â”œâ”€â”€ ï¿½ Makefile                          # Comandos Docker Compose (raÃ­z)
â”œâ”€â”€ ï¿½ monitor.sh                        # Script de monitoreo de recursos
â”œâ”€â”€ ï¿½ requirements.txt                  # Dependencias Python
â”œâ”€â”€ ï¿½ .env                              # Variables de entorno (crear)
â””â”€â”€ ğŸ“– README.md                         # Este archivo
```

### DescripciÃ³n de Servicios (Docker Compose)

| Servicio | Puerto | DescripciÃ³n | TecnologÃ­a |
|----------|--------|-------------|------------|
| **nginx** | 80 | Proxy reverso y balanceador | Nginx |
| **storeapi** | 8000 (interno) | API REST principal | FastAPI + Python 3.11 |
| **worker** | - | Procesador asÃ­ncrono de videos | Python 3.11 + FFmpeg |
| **db** | 5432 | Base de datos relacional | PostgreSQL 15 |
| **kafka** | 9092 | Message broker para tareas | Apache Kafka (KRaft) |
| **redis** | 6379 | CachÃ© para ranking | Redis 7 |

### Flujo de Datos

1. **Upload**: Cliente â†’ Nginx (80) â†’ StoreAPI â†’ S3/Local + Kafka
2. **Procesamiento**: Kafka â†’ Worker â†’ FFmpeg â†’ S3/Local â†’ DB (update status)
3. **Consultas**: Cliente â†’ Nginx â†’ StoreAPI â†’ Redis (cache) / DB â†’ Response

---
