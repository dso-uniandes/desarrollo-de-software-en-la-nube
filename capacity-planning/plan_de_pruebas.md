# üß™ Plan de An√°lisis de Capacidad

## 1. Objetivo General

Evaluar la **capacidad m√°xima** que puede soportar la aplicaci√≥n en sus dos componentes cr√≠ticos:
1. **Capa Web (API HTTP):** endpoint de subida de videos `/api/videos/upload`
2. **Capa Worker:** procesamiento as√≠ncrono de videos con FFmpeg

El prop√≥sito es identificar l√≠mites de **concurrencia, rendimiento y estabilidad**, establecer una l√≠nea base de desempe√±o y proponer acciones de mejora basadas en evidencia.

---

## 2. Objetivos Espec√≠ficos

| N¬∫ | Objetivo | M√©trica asociada |
|----|-----------|------------------|
| 1 | Determinar el n√∫mero m√°ximo de usuarios concurrentes soportados en upload sin degradaci√≥n | p95 ‚â§ 1s, error rate ‚â§ 5% |
| 2 | Medir la capacidad de procesamiento de los workers (videos/minuto) | Throughput y tiempo medio de servicio |
| 3 | Identificar cuellos de botella en CPU, memoria, red o almacenamiento | M√©tricas del host y contenedores |
| 4 | Evaluar la estabilidad bajo carga sostenida y picos repentinos | Desviaci√≥n est√°ndar de latencia y uso de recursos |
| 5 | Validar el tiempo de aceptaci√≥n de archivos de diferentes tama√±os | Tiempo de respuesta para 5 MB, 50 MB, 100 MB |
| 6 | Documentar resultados y recomendaciones de escalabilidad | Informe final con evidencias y gr√°ficos |

---

## 3. Descripci√≥n General

Este plan de pruebas eval√∫a dos componentes cr√≠ticos de la arquitectura:

### 3.1 Capa Web (API HTTP)
- **Endpoint bajo prueba:** `POST /api/videos/upload`
- **Funci√≥n:** Recepci√≥n de archivos multipart/form-data, validaci√≥n, almacenamiento temporal y encolado de tarea
- **Tecnolog√≠a:** FastAPI (Python), almacenamiento S3/local, mensajer√≠a Kafka
- **M√©tricas clave:** Tiempo de aceptaci√≥n, RPS, concurrencia m√°xima, error rate

### 3.2 Capa Worker
- **Funci√≥n:** Procesamiento as√≠ncrono de videos con FFmpeg (branding, trim, concatenaci√≥n)
- **Tecnolog√≠a:** Python, Kafka Consumer, FFmpeg, S3
- **M√©tricas clave:** Videos procesados/minuto, tiempo medio de procesamiento, throughput

Las pruebas se ejecutar√°n en **entorno local** con **Docker Compose**, garantizando un aislamiento controlado y replicable del sistema.

---

## 4. Tipos de Pruebas

| Tipo | Objetivo | Descripci√≥n |
|------|----------|-------------|
| **Capacidad** | Determinar m√°ximo de usuarios concurrentes y RPS sostenido | Incremento progresivo de carga hasta detectar degradaci√≥n |
| **Carga** | Evaluar comportamiento con niveles crecientes de solicitudes | Rampas ascendentes con plateaus de estabilizaci√≥n |
| **Estr√©s** | Analizar respuesta ante sobrecarga extrema | Incremento s√∫bito hasta saturaci√≥n y observar recuperaci√≥n |
| **Picos (Spike)** | Evaluar recuperaci√≥n tras picos repentinos | Carga instant√°nea 10x‚Äì20x durante 20‚Äì30s |
| **Sostenida (Soak)** | Validar estabilidad a largo plazo | 1‚Äì2 horas a carga media para detectar fugas |
| **Escalabilidad Worker** | Validar impacto de aumentar paralelismo | Comparar throughput con 1/2/4 workers |

---

## 5. Criterios de Aceptaci√≥n

### 5.1 Capa Web (Upload)
- ‚úÖ **p95 de latencia ‚â§ 1 segundo** para archivos de hasta 100 MB
- ‚úÖ **Error rate ‚â§ 5%** (excluyendo errores esperados como 400/413)
- ‚úÖ **Sin resets ni timeouts an√≥malos**
- ‚úÖ **CPU del contenedor `storeapi` ‚â§ 85%** sostenido
- ‚úÖ **Tiempo de aceptaci√≥n:**
  - 5 MB: ‚â§ 500 ms
  - 50 MB: ‚â§ 1.5 s
  - 100 MB: ‚â§ 2 s
- ‚úÖ **Validaci√≥n de errores controlados:**
  - 400 para tipos de archivo inv√°lidos
  - 413 para archivos que exceden l√≠mite configurado

### 5.2 Capa Worker
- ‚úÖ **La cola no debe crecer indefinidamente** durante prueba sostenida
- ‚úÖ **Throughput estable** seg√∫n configuraci√≥n de paralelismo
- ‚úÖ **CPU del contenedor `worker` ‚â§ 85%** sostenido
- ‚úÖ **Sin fallos de procesamiento** por timeout o recursos
- ‚úÖ **Tiempo de procesamiento predecible** seg√∫n tama√±o de archivo

---

## 6. Datos de Prueba

### 6.1 Para Capa Web
- **Usuarios simulados:** 5, 50, 100, 200, 300, 400
- **Duraci√≥n por escenario:** 1‚Äì10 minutos
- **Tama√±os de archivo:** 5 MB, 50 MB, 100 MB
- **Formato de archivos:** MP4 (v√°lidos) y archivos inv√°lidos para pruebas de error
- **Credenciales:** Usuario de prueba pre-creado (test@example.com / pass123)

### 6.2 Para Capa Worker
- **Mensajes en cola:** 10 a 500 por ejecuci√≥n
- **Tama√±os de video:** 50 MB, 100 MB
- **Configuraciones de paralelismo:** 1, 2, 4 workers
- **Operaciones FFmpeg:** Intro (2.5s) + Video (max 30s) + Outro (2.5s)

---

## 7. Iteraciones y Repetibilidad

- Cada escenario se repetir√° **m√≠nimo 5 veces** para validar consistencia
- Se calcular√°n: **promedio, desviaci√≥n est√°ndar y percentiles** (p50, p90, p95, p99)
- Se identificar√°n y justificar√°n **valores at√≠picos**
- Se mantendr√° un **baseline** por iteraci√≥n del desarrollo para comparaci√≥n

---

## 8. Configuraci√≥n del Sistema

### 8.1 Arquitectura

```mermaid
graph TD
  A[Newman/Postman<br/>Generador de carga] --> B[Nginx<br/>Reverse Proxy]
  B --> C[StoreAPI<br/>FastAPI]
  C --> D[(PostgreSQL<br/>Base de datos)]
  C --> E[(Redis<br/>Cach√© opcional)]
  C --> F[S3/Local<br/>Almacenamiento]
  C --> G[Kafka<br/>Message Broker]
  G --> H[Worker<br/>FFmpeg Processor]
  H --> F
  H --> D
  
  I[Monitor<br/>Docker Stats] -.-> C
  I -.-> H
  I -.-> G
  
  style C fill:#4A90E2
  style H fill:#E27B4A
  style A fill:#50C878
```

### 8.2 Servicios Docker Compose

| Servicio | Imagen/Tecnolog√≠a | Prop√≥sito |
|----------|-------------------|-----------|
| `nginx` | nginx:latest | Proxy reverso y balanceo de carga |
| `storeapi` | FastAPI (Python 3.11) | API REST para manejo de videos |
| `worker` | Python 3.11 + FFmpeg | Procesamiento as√≠ncrono de videos |
| `anb-database` | PostgreSQL 15 | Persistencia de metadatos |
| `anb-redis` | Redis 7 | Cach√© (opcional) |
| `kafka` | Apache Kafka | Cola de mensajes para tareas |

### 8.3 Host Local (Requisitos M√≠nimos)

- **CPU:** 8 n√∫cleos (m√≠nimo 4 dedicados a Docker)
- **RAM:** 16 GB (m√≠nimo 8 GB disponibles)
- **Disco:** 50 GB libres (para videos y logs)
- **Sistema operativo:** macOS / Linux
- **Docker:** Docker Desktop 4.x o Docker Engine 20.x

---

## 9. Herramientas de Prueba

| Herramienta | Uso | Versi√≥n | Comando de instalaci√≥n |
|-------------|-----|---------|------------------------|
| **Newman** | Ejecuci√≥n automatizada de colecciones Postman | 5.6.3+ | `npm install -g newman` |
| **Postman** | Dise√±o de colecciones y verificaci√≥n manual | √öltima | Descargar de postman.com |
| **Docker Stats** | Monitoreo de recursos de contenedores | Built-in | - |
| **monitor.sh** | Script personalizado para captura de m√©tricas | Custom | Incluido en el proyecto |
| **Python 3.11** | Inyecci√≥n de mensajes en Kafka (worker tests) | 3.11+ | - |
| **jq** | Procesamiento de logs JSON | √öltima | `brew install jq` |

---

## 10. M√©tricas

### 10.1 M√©tricas de Aplicaci√≥n

| Categor√≠a | M√©trica | Descripci√≥n | Unidad |
|-----------|---------|-------------|--------|
| **Latencia** | p50, p90, p95, p99 | Percentiles de tiempo de respuesta | ms |
| **Throughput** | RPS (Requests Per Second) | Solicitudes procesadas por segundo | req/s |
| **Errores** | Error Rate | Porcentaje de respuestas 4xx/5xx | % |
| **Disponibilidad** | Uptime | Tiempo sin errores 5xx | % |
| **Capacidad** | Max VUs | Usuarios concurrentes m√°ximos sin degradaci√≥n | usuarios |

### 10.2 M√©tricas de Worker

| M√©trica | Descripci√≥n | Unidad |
|---------|-------------|--------|
| **Videos procesados/min** | Throughput del worker | videos/min |
| **Tiempo medio de procesamiento** | Tiempo promedio por video | segundos |
| **Tiempo por fase** | DB Fetch, S3 Download, FFmpeg, DB Update | segundos |
| **Cola pendiente** | Mensajes en espera en Kafka | mensajes |
| **Error rate** | Fallos de procesamiento | % |

### 10.3 M√©tricas de Infraestructura

| Recurso | M√©tricas | Herramienta |
|---------|----------|-------------|
| **CPU** | Utilizaci√≥n %, carga promedio | docker stats, monitor.sh |
| **Memoria** | Uso MB, porcentaje, swap | docker stats |
| **Red** | Ancho de banda (NetIO) | docker stats |
| **Disco** | IO (BlockIO), espacio usado | docker stats, df -h |
| **Base de datos** | Conexiones activas, latencia de consultas | Logs de PostgreSQL |

---

## 11. Escenarios de Prueba

### 11.1 Escenario 1: Capacidad de la Capa Web (Upload)

**Objetivo:** Determinar el m√°ximo de usuarios concurrentes y RPS que soporta `POST /api/videos/upload` cumpliendo SLOs.

**Estrategia:**
1. **Smoke Test:** 5 VUs durante 1 minuto (validaci√≥n b√°sica)
2. **Ramp Test:** Incremento gradual 0 ‚Üí X VUs en 3 minutos, mantener 5 minutos
3. **Capacity Test:** Encontrar X m√°ximo donde p95 ‚â§ 1s y error rate ‚â§ 5%
4. **Sustained Test:** 5 minutos al 80% de X para validar estabilidad

**Configuraci√≥n Newman:**
```bash
# Smoke test (5 usuarios, 60 iteraciones total)
newman run postman/collection.json \
  -e postman/environment.json \
  --iteration-count 60 \
  --delay-request 1000 \
  -r cli,html \
  --reporter-html-export postman/report_smoke.html

# Ramp test (incremento gradual simulado con m√∫ltiples ejecuciones)
for users in 50 100 150 200 250 300; do
  echo "Testing with $users users..."
  newman run postman/collection.json \
    -e postman/environment.json \
    --iteration-count $users \
    --delay-request 200 \
    -r cli,html \
    --reporter-html-export postman/report_${users}users.html
  sleep 30  # pausa entre escalones
done
```

**Criterios de √©xito:**
- ‚úÖ p95 ‚â§ 1s
- ‚úÖ Error rate ‚â§ 5% (excluyendo 400/413 esperados)
- ‚úÖ CPU API ‚â§ 85%
- ‚úÖ Sin resets/timeouts an√≥malos

**Salidas esperadas:**
- Curva: Usuarios concurrentes vs. p95 latencia
- Gr√°fico: RPS vs. Error rate
- Identificaci√≥n de capacidad m√°xima
- Reporte HTML de Newman con estad√≠sticas detalladas

---

### 11.2 Escenario 2: Rendimiento de la Capa Worker

**Objetivo:** Medir videos/min procesados a distintos tama√±os y niveles de paralelismo.

**Estrategia:**
1. **Bypass de la capa web:** Inyectar mensajes directamente en Kafka topic `video_tasks`
2. **Variables experimentales:**
   - Tama√±os: 50 MB, 100 MB
   - Paralelismo: 1, 2, 4 workers
3. **Medici√≥n:** Saturaci√≥n (aumentar tareas) y sostenida (mantener backlog fijo)

**Inyecci√≥n de mensajes (Python script):**
```python
# worker_load_test.py
from confluent_kafka import Producer
import json
import time

producer = Producer({'bootstrap.servers': 'localhost:9092'})

# Inyectar 100 tareas
for i in range(100):
    message = {
        'task_id': f'test-task-{i}',
        'video_id': 1,  # ID de video existente en DB
    }
    producer.produce('video_tasks', json.dumps(message))
    if i % 10 == 0:
        print(f'Enqueued {i} tasks...')
        time.sleep(1)  # control de ritmo

producer.flush()
print('All tasks enqueued!')
```

**Ejecuci√≥n:**
```bash
# Con 1 worker (default)
docker-compose up -d worker

# Con 2 workers
docker-compose up -d --scale worker=2

# Con 4 workers
docker-compose up -d --scale worker=4

# Inyectar carga
python worker_load_test.py

# Monitorear procesamiento
docker logs -f worker | grep "TOTAL TASK TIME"
```

**M√©tricas a calcular:**
- Videos procesados/minuto = (Total videos / Tiempo total en min)
- Tiempo medio de servicio = Promedio de "TOTAL TASK TIME"
- Descomposici√≥n: DB Fetch, S3 Download, FFmpeg, DB Update
- Pendiente de la cola = Mensajes encolados - Mensajes procesados

**Criterios de √©xito:**
- ‚úÖ Capacidad nominal estable (throughput constante)
- ‚úÖ Cola no crece indefinidamente (pendiente ‚âà 0 en sostenidas)
- ‚úÖ CPU worker ‚â§ 85%
- ‚úÖ Sin errores de procesamiento

**Salidas esperadas:**
- Tabla: Capacidad por configuraci√≥n (1/2/4 workers) y tama√±o (50/100 MB)
- Gr√°fico: Throughput vs. Paralelismo
- Identificaci√≥n de cuellos de botella (CPU, IO, S3, DB)

---

## 12. Ejecuci√≥n de Pruebas

### üì¶ Requisitos

```bash
# 1. Activar el entorno virtual
source ../.venv/bin/activate

# 2. Instalar dependencias (matplotlib para gr√°ficas)
cd capacity-planning
pip install -r requirements.txt
```

### üß™ Tipos de Tests Disponibles

Todos los comandos se ejecutan desde la ra√≠z del proyecto:

```bash
# Smoke Test - Validaci√≥n r√°pida (5 usuarios)
make -C ./capacity-planning/ test-smoke

# Capacity Test - Encontrar l√≠mite (50‚Üí300 usuarios)
make -C ./capacity-planning/ test-capacity

# Ramp Test - Rampa gradual
make -C ./capacity-planning/ test-ramp

# Sustained Test - Carga sostenida (10 min)
make -C ./capacity-planning/ test-sustained

# Stress Test - Sobrecarga hasta fallo
make -C ./capacity-planning/ test-stress

# Spike Test - Picos repentinos
make -C ./capacity-planning/ test-spike
```

**Nota**: Cada test autom√°ticamente:
- Inicia monitores de recursos
- Ejecuta Newman con la carga configurada
- Espera a que el worker termine de procesar
- Genera estad√≠sticas y gr√°ficas
- Guarda reportes en `postman/results/`

### üìä Generar Estad√≠sticas y Gr√°ficas

Si necesitas regenerar estad√≠sticas/gr√°ficas de un test ya ejecutado:

```bash
# Opci√≥n 1: Interactivo (te pide el timestamp)
make -C ./capacity-planning/ calculate-stats

# Opci√≥n 2: Directo con timestamp
cd capacity-planning
source ../.venv/bin/activate
python3 calculate_stats.py 20251019_170416
python3 generate_graphs.py 20251019_170416
```

### üìà Ver Resultados

```bash
# Ver estad√≠sticas en consola
make -C ./capacity-planning/ view-stats

# Abrir gr√°ficas generadas
make -C ./capacity-planning/ open-graphs

# Ver reportes HTML de Newman
make -C ./capacity-planning/ open-latest-report
```

### üìÅ Archivos Generados

Ubicaci√≥n: `capacity-planning/postman/results/`

**Reportes de Newman:**
- `report_[test]_[timestamp].html` - Reporte visual con m√©tricas HTTP
- `report_[test]_[timestamp].json` - Datos estructurados (usado por scripts)

**Datos de monitoreo (CSV):**
- `container_stats_[timestamp].csv` - CPU, memoria, red, disco por contenedor
- `worker_timing_[timestamp].csv` - Tiempos de procesamiento por tarea
- `summary_[timestamp].csv` - Resumen consolidado (API + containers + worker)

**Gr√°ficas (PNG):**
- `container_resources.png` - Recursos por contenedor (series de tiempo)
- `worker_timing.png` - Tiempos de procesamiento (√°rea apilada)
- `worker_breakdown_pie.png` - Desglose de tiempos (barra + pie chart)
- `newman_api_metrics.png` - Dashboard de API (4 paneles: histograma, tendencia, success rate, estad√≠sticas)

---

## 13. Interpretaci√≥n de Resultados

### Criterios de √âxito

- **p95 ‚â§ 1s** = Sistema cumple SLO ‚úÖ
- **Error rate ‚â§ 5%** = Disponibilidad aceptable ‚úÖ
- **CPU < 85%** = Margen para picos de tr√°fico ‚úÖ
- **Worker queue estable** = Throughput suficiente ‚úÖ

### Resultados

- **Smoke Test - Validaci√≥n r√°pida (5 usuarios)**
  
  ```bash
  make -C ./capacity-planning/ test-smoke
  ```

  **M√©tricas de API:**
  
  ![Newman API Metrics](./resultados/Escenario1/newman_api_metrics.png)

  **Recursos de Contenedores:**
  
  ![Container Resources](./resultados/Escenario1/container_resources.png)

  **Tiempos de Worker:**
  
  ![Worker Timing](./resultados/Escenario1/worker_timing.png)

  **Desglose de Procesamiento:**
  
  ![Worker Breakdown](./resultados/Escenario1/worker_breakdown_pie.png)

- **Capacity Test - Encontrar l√≠mite (50‚Üí300 usuarios)**
  
  ```bash
  make -C ./capacity-planning/ test-capacity
  ```

  **50 Usuarios:**
  
  | API Metrics | Container Resources |
  |-------------|---------------------|
  | ![API 50](./resultados/Escenario2/newman_api_metrics_50_users.png) | ![Resources 50](./resultados/Escenario2/container_resources_50_users.png) |
  
  | Worker Timing | Worker Breakdown |
  |---------------|------------------|
  | ![Timing 50](./resultados/Escenario2/worker_timing_50_users.png) | ![Breakdown 50](./resultados/Escenario2/worker_breakdown_pie_50_users.png) |

  **100 Usuarios:**
  
  | API Metrics | Container Resources |
  |-------------|---------------------|
  | ![API 100](./resultados/Escenario2/newman_api_metrics_100_users.png) | ![Resources 100](./resultados/Escenario2/container_resources_100_users.png) |
  
  | Worker Timing | Worker Breakdown |
  |---------------|------------------|
  | ![Timing 100](./resultados/Escenario2/worker_timing_100_users.png) | ![Breakdown 100](./resultados/Escenario2/worker_breakdown_pie_100_users.png) |

  **150 Usuarios:**
  
  | API Metrics | Container Resources |
  |-------------|---------------------|
  | ![API 150](./resultados/Escenario2/newman_api_metrics_150_users.png) | ![Resources 150](./resultados/Escenario2/container_resources_150_users.png) |
  
  | Worker Timing | Worker Breakdown |
  |---------------|------------------|
  | ![Timing 150](./resultados/Escenario2/worker_timing_150_users.png) | ![Breakdown 150](./resultados/Escenario2/worker_breakdown_pie_150_users.png) |

  **200 Usuarios:**
  
  | API Metrics | Container Resources |
  |-------------|---------------------|
  | ![API 200](./resultados/Escenario2/newman_api_metrics_200_users.png) | ![Resources 200](./resultados/Escenario2/container_resources_200_users.png) |
  
  | Worker Timing | Worker Breakdown |
  |---------------|------------------|
  | ![Timing 200](./resultados/Escenario2/worker_timing_200_users.png) | ![Breakdown 200](./resultados/Escenario2/worker_breakdown_pie_200_users.png) |

  **250 Usuarios:**
  
  | API Metrics | Container Resources |
  |-------------|---------------------|
  | ![API 250](./resultados/Escenario2/newman_api_metrics_250_users.png) | ![Resources 250](./resultados/Escenario2/container_resources_250_users.png) |
  
  > **Nota:** A partir de 250 usuarios, las m√©tricas del worker no se incluyen ya que el tiempo de procesamiento se vuelve excesivamente largo, haciendo impr√°ctico esperar a que termine el procesamiento de todos los videos encolados. El foco de estas pruebas de alta carga est√° en la capacidad de la API para aceptar solicitudes, no en el throughput del worker que ya no cumple con la metrica esperada.

  **300 Usuarios:**
  
  | API Metrics | Container Resources |
  |-------------|---------------------|
  | ![API 300](./resultados/Escenario2/newman_api_metrics_300_users.png) | ![Resources 300](./resultados/Escenario2/container_resources_300_users.png) |
  
  > **Nota:** Las gr√°ficas del worker no est√°n disponibles para cargas de 250+ usuarios debido a los tiempos de procesamiento prolongados.

- **Ramp Test - Rampa gradual**
  
  ```bash
  make -C ./capacity-planning/ test-ramp
  ```

  **50 Usuarios:**
  
  | API Metrics | Container Resources |
  |-------------|---------------------|
  | ![API 50](./resultados/Esceneario3/newman_api_metrics_50_users.png) | ![Resources 50](./resultados/Esceneario3/container_resources_50_users.png) |

  **100 Usuarios:**
  
  | API Metrics | Container Resources |
  |-------------|---------------------|
  | ![API 100](./resultados/Esceneario3/newman_api_metrics_100_users.png) | ![Resources 100](./resultados/Esceneario3/container_resources_100_users.png) |

  **200 Usuarios:**
  
  | API Metrics | Container Resources |
  |-------------|---------------------|
  | ![API 200](./resultados/Esceneario3/newman_api_metrics_200_users.png) | ![Resources 200](./resultados/Esceneario3/container_resources_200_users.png) |

  **300 Usuarios:**
  
  | API Metrics | Container Resources |
  |-------------|---------------------|
  | ![API 300](./resultados/Esceneario3/newman_api_metrics_300_users.png) | ![Resources 300](./resultados/Esceneario3/container_resources_300_users.png) |

  > **Nota:** En el Ramp Test solo se muestran m√©tricas de API y recursos de contenedores, ya que el enfoque est√° en evaluar la capacidad de aceptaci√≥n de solicitudes bajo carga gradual incremental.


- **Stress Test - Sobrecarga hasta fallo**
  
  ```bash
  make -C ./capacity-planning/ test-stress
  ```

  **M√©tricas de API:**
  
  ![Newman API Metrics](./resultados/Escenario4/newman_api_metrics.png)

  **Recursos de Contenedores:**
  
  ![Container Resources](./resultados/Escenario4/container_resources.png)

  > **Nota:** El Stress Test eval√∫a el comportamiento del sistema bajo sobrecarga extrema, buscando identificar el punto de ruptura y la capacidad de recuperaci√≥n. Solo se muestran m√©tricas de API y recursos de contenedores.

- **Sustained Con Postman 100 Parallel Users**
  

  **Prueba de Carga Sostenida (Postman):**
  
  ![Sustained Test Postman](./resultados/EscenarioExtra/image.png)

  > **Nota:** Esta prueba eval√∫a la estabilidad del sistema bajo carga sostenida de 100 usuarios concurrentes durante un per√≠odo prolongado, utilizando Postman como herramienta de generaci√≥n de carga.

### Conclusiones del An√°lisis de Capacidad

####  Desempe√±o Bajo Carga Ligera (Smoke Test)

El **Escenario 1 (Smoke Test)** demostr√≥ que tanto el API como el worker funcionan correctamente bajo carga ligera. Los resultados muestran:

- ‚úÖ **API**: Tiempos de respuesta muy bajos y estables, con la mayor√≠a de las peticiones complet√°ndose en menos de 500ms
- ‚úÖ **Worker**: Procesamiento eficiente de videos con tiempos razonables y desglose predecible entre las diferentes fases (DB Fetch, S3 Download, FFmpeg, DB Update)
- ‚úÖ **Recursos**: Uso moderado de CPU y memoria en todos los contenedores
- ‚úÖ **Sin degradaci√≥n**: No se observaron errores ni timeouts durante la prueba

Este escenario establece la **l√≠nea base de desempe√±o** del sistema y confirma que la arquitectura es s√≥lida para cargas normales de operaci√≥n.

#### Limitaciones del Worker en Cargas Altas

A partir del **Escenario 2 (Capacity Test)**, se identific√≥ un cuello de botella cr√≠tico en la capa de procesamiento:

- ‚ö†Ô∏è **Con >50 videos encolados**: Los mensajes en la cola de Kafka permanec√≠an en espera por tiempos significativamente mayores a los esperados
- ‚ö†Ô∏è **Con 200+ videos**: El tiempo de procesamiento completo superaba **30 minutos**, haciendo impr√°ctico esperar la finalizaci√≥n del procesamiento
- ‚ö†Ô∏è **Decisi√≥n metodol√≥gica**: Para pruebas de capacidad con 250+ usuarios, se **excluyeron las m√©tricas del worker** del an√°lisis, enfoc√°ndose √∫nicamente en la capacidad del API para aceptar solicitudes

**Implicaciones:**

- El throughput del worker (con configuraci√≥n actual de 1 worker) es insuficiente para procesar la carga generada por ~100 usuarios concurrentes
- El procesamiento de video con FFmpeg es CPU-intensivo y secuencial, creando un backlog que crece m√°s r√°pido de lo que puede ser procesado
- Se requiere **escalamiento horizontal** (m√°s workers) para manejar picos de carga sostenidos

### 14.3 Limitaciones de la Herramienta de Pruebas (Newman)

La elecci√≥n de **Newman** como herramienta de generaci√≥n de carga present√≥ limitaciones significativas:

- ‚ùå **Sin concurrencia real**: Newman ejecuta iteraciones secuencialmente con delays configurados, pero no genera **usuarios verdaderamente paralelos** como lo hace JMeter
- ‚ùå **No se alcanz√≥ el punto de ruptura del API**: En ninguna de las pruebas (50, 100, 150, 200, 250, 300 "usuarios") se logr√≥ saturar o tumbar el API
- ‚úÖ **Validaci√≥n con Postman**: La prueba del **EscenarioExtra** con Postman Collection Runner demostr√≥ que incluso con **100 usuarios concurrentes reales** y casi **6,000 peticiones**, el API mantuvo estabilidad sin errores cr√≠ticos

**Conclusi√≥n clave**: El API tiene una **capacidad mucho mayor** de la que pudimos medir con Newman. Las pruebas actuales validan la estabilidad bajo carga secuencial incremental, pero no determinan el l√≠mite real de concurrencia del sistema.

**Posibles Mejoras para futuros tests:**

- Migrar a **Apache JMeter** o **k6** para pruebas de carga con concurrencia real
- Ejecutar pruebas con 500, 1000, 2000+ usuarios concurrentes simult√°neos
- Configurar m√∫ltiples workers (2, 4, 8) para validar escalamiento horizontal
- Implementar monitoreo de m√©tricas de Kafka (lag de consumidores, throughput de mensajes)

---

