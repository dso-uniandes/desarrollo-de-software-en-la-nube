# üß™ Plan de An√°lisis de Capacidad

## 1. Objetivo General

Evaluar la **capacidad m√°xima** que puede soportar la aplicaci√≥n en sus dos componentes cr√≠ticos:

1. **Capa Web (API HTTP):** ahora servida por API Gateway + AWS Lambda
2. **Capa Worker:** procesamiento as√≠ncrono de videos con Lambda disparada por SQS

El prop√≥sito es identificar l√≠mites de **concurrencia, rendimiento y estabilidad**, establecer una l√≠nea base de desempe√±o y proponer acciones de mejora basadas en evidencia.

---

## 2. Objetivos Espec√≠ficos

| N¬∫ | Objetivo | M√©trica asociada |
|----|-----------|------------------|
| 1 | Determinar el n√∫mero m√°ximo de usuarios concurrentes soportados en la API sin degradaci√≥n | p95 ‚â§ 1s, error rate ‚â§ 5% |
| 2 | Medir la capacidad de procesamiento de los workers (videos/minuto) | Throughput y tiempo medio de servicio |
| 3 | Identificar cuellos de botella en CPU, memoria, red o almacenamiento | M√©tricas del host y contenedores |
| 4 | Evaluar la estabilidad bajo carga sostenida y picos repentinos | Desviaci√≥n est√°ndar de latencia y uso de recursos |
| 5 | Validar el tiempo de respuesta de endpoints bajo diferentes cargas | Tiempo de respuesta p95, p99 bajo carga variable |
| 6 | Documentar resultados y recomendaciones de escalabilidad | Informe final con evidencias y gr√°ficos |

---

## 3. Descripci√≥n General

Este plan de pruebas eval√∫a dos componentes cr√≠ticos de la arquitectura:

### 3.1 Capa Web (API HTTP)

- **Endpoints bajo prueba:** `POST /api/auth/login`
- **Funci√≥n:** Autenticaci√≥n de usuarios mediante validaci√≥n de credenciales
- **Tecnolog√≠a:** FastAPI (Python), almacenamiento S3, mensajer√≠a SQS
- **M√©tricas clave:** Latencia (p50, p95, p99), RPS, concurrencia m√°xima, error rate

### 3.2 Capa Worker

- **Funci√≥n:** Procesamiento as√≠ncrono de videos con FFmpeg (branding, trim, concatenaci√≥n)
- **Tecnolog√≠a:** Python, SQS Consumer, FFmpeg, S3
- **M√©tricas clave:** Videos procesados/minuto, tiempo medio de procesamiento, throughput

---

## 4. Tipos de Pruebas

### 4.1 Escenario 1 - Capa Web

- **Sanidad (Smoke):** 5 usuarios durante 1 minuto para validar que todo responde y la telemetr√≠a est√° activa
- **Escalamiento r√°pido (Ramp):** iniciar en 0 y aumentar hasta X usuarios en 3 minutos; mantener 5 minutos. Repetir con X creciente (p. ej., 100 ‚Üí 200 ‚Üí 300) hasta observar degradaci√≥n
- **Sostenida corta:** ejecutar 5 minutos en el 80% de X (el mejor nivel previo sin degradaci√≥n) para confirmar estabilidad

### 4.2 Plan B - Capa Worker

- **Pruebas de saturaci√≥n:** subir la cantidad de tareas progresivamente en la cola
- **Pruebas sostenidas:** mantener un n√∫mero fijo de archivos en la cola que no la sature

---

## 5. Criterios de Aceptaci√≥n

### 5.1 Capa Web

- ‚úÖ **p95 de latencia ‚â§ 1 segundo**
- ‚úÖ **Error rate ‚â§ 5%** (excluyendo errores esperados como 401 para credenciales inv√°lidas)
- ‚úÖ **Sin resets ni timeouts an√≥malos**
- ‚úÖ **CPU de instancias EC2 ‚â§ 85%** sostenido
- ‚úÖ **Tiempo de respuesta consistente:** Latencia estable independientemente del n√∫mero de usuarios concurrentes
- ‚úÖ **Validaci√≥n de errores controlados:**
  - 401 para credenciales inv√°lidas o incorrectas
  - 422 para datos de entrada mal formateados

### 5.2 Capa Worker

- ‚úÖ **La cola no debe crecer indefinidamente** durante prueba sostenida
- ‚úÖ **Throughput estable** seg√∫n configuraci√≥n de paralelismo
- ‚úÖ **CPU de instancias worker ‚â§ 85%** sostenido
- ‚úÖ **Sin fallos de procesamiento** por timeout o recursos
- ‚úÖ **Tiempo de procesamiento predecible** seg√∫n tama√±o de archivo

---

## 6. Datos de Prueba

### 6.1 Para Capa Web

- **Usuarios simulados:** 5, 50, 100, 200, 300, 400
- **Duraci√≥n por escenario:** 1‚Äì10 minutos
- **Credenciales v√°lidas:** Usuario de prueba pre-creado (test@example.com / pass123)
- **Credenciales inv√°lidas:** Para pruebas de error (usuario inexistente, contrase√±a incorrecta)
- **Payload de login:** JSON con email y contrase√±a

### 6.2 Para Capa Worker

- **Mensajes en cola:** 10 a 500 por ejecuci√≥n
- **Tama√±os de video:** 50 MB, 100 MB
- **Configuraciones de paralelismo:** 1, 2, 4 workers (instancias)
- **Operaciones FFmpeg:** Intro (2.5s) + Video (max 30s) + Outro (2.5s)

---

## 7. Escenarios de Prueba

### 7.1 Escenario 1 - Capacidad de la Capa Web (Usuarios Concurrentes)

**Objetivo:** Determinar el n√∫mero de usuarios concurrentes (y RPS asociado) que la API soporta cumpliendo SLOs, sin estar limitado por la capa as√≠ncrona.

#### Estrategia de Implementaci√≥n

- **Desacoplar la capa worker:** en endpoints de carga, devolver 202 y redirigir a un mock de cola que acepte mensajes en memoria y responda instant√°neamente.

#### Escenarios de Prueba

1. **Sanidad (Smoke):** 5 usuarios durante 1 minuto para validar que todo responde y la telemetr√≠a est√° activa.

2. **Escalamiento r√°pido (Ramp):** iniciar en 0 y aumentar hasta X usuarios en 3 minutos; mantener 5 minutos. Repetir con X creciente (p. ej., 100 ‚Üí 200 ‚Üí 300) hasta observar degradaci√≥n.

3. **Sostenida corta:** ejecutar 5 minutos en el 80% de X (el mejor nivel previo sin degradaci√≥n) para confirmar estabilidad.

#### Criterios de √âxito/Fallo

**Capacidad m√°xima:** mayor n√∫mero de usuarios concurrentes que cumple:
- ‚úÖ **p95 de endpoints ‚â§ 1 s**
- ‚úÖ **Errores (4xx evitables/5xx) ‚â§ 5%**
- ‚úÖ **Sin resets/timeouts an√≥malos** ni throttling del almacenamiento

**Si se supera capacidad m√°xima:** registrar el primer KPI que se degrada (CPU del API, ancho de banda, etc) y usarlo como gu√≠a de mejora.

#### Herramientas Sugeridas

- **Generador:** JMeter
- **Observabilidad:** Prometheus/Grafana + APM (OpenTelemetry)

#### Salidas Esperadas

- Curva usuarios‚Üílatencia/errores
- RPS sostenido a capacidad m√°xima (ej: "Soporta 450 usuarios concurrentes con 320 RPS manteniendo p95 1,0 s")
- Bottlenecks con evidencias (CPU 90% en API, saturaci√≥n de ancho de banda de subida, etc.)

---

### 7.2 Plan B ‚Äî Rendimiento de la Capa Worker (Videos/min)

**Objetivo:** Medir cu√°ntos videos por minuto procesa el/los worker(s) a distintos niveles de paralelismo y tama√±os de archivo.

#### Estrategia de Implementaci√≥n

- **Bypass de la web:** inyectar directamente mensajes en la cola (script/productor) con payloads realistas (rutas a archivos en storage de pruebas).

#### Dise√±o Experimental

- **Tama√±o de video:** 50 MB, 100 MB
- **Concurrencia de worker:** 1, 2, 4 procesos/hilos por nodo

Para cada combinaci√≥n:
- **Ejecutar pruebas de saturaci√≥n:** subir la cantidad de tareas progresivamente en la cola
- **Ejecutar pruebas sostenidas:** mantener un n√∫mero fijo de archivos en la cola que no la sature

#### M√©tricas y C√°lculos

- **Throughput observado:** X = videos procesados por minuto
- **Tiempo medio de servicio:** S = tiempo_proceso_promedio por video

#### Criterios de √âxito/Fallo

- ‚úÖ **Capacidad nominal:** (videos/min)
- ‚úÖ **Estabilidad:** cola no crece sin control (tendencia ~0) durante la prueba

#### Herramientas Sugeridas

- **Productor de mensajes:** scripts Python/Go contra Redis/RabbitMQ/SQS
- **Trazabilidad de jobs:** IDs correlacionados (enqueue‚Üístart‚Üíend)
- **Perfilado del worker:** m√©tricas (CPU, IO, red, etc)

#### Salidas Esperadas

- Tabla de capacidad por tama√±o y configuraci√≥n (ej: "1 nodos √ó 4 hilos ‚Üí 18.5 videos/min a 200 MB")
- Puntos de saturaci√≥n y cuellos de botella (CPU, decodificaci√≥n, ancho de banda, temp disk)

---

## 8. M√©tricas a Capturar

### 8.1 M√©tricas de Aplicaci√≥n (Capa Web)

| Categor√≠a | M√©trica | Descripci√≥n | Unidad |
|-----------|---------|-------------|--------|
| **Latencia** | p50, p90, p95, p99 | Percentiles de tiempo de respuesta | ms |
| **Throughput** | RPS (Requests Per Second) | Solicitudes procesadas por segundo | req/s |
| **Errores** | Error Rate | Porcentaje de respuestas 4xx/5xx | % |
| **Disponibilidad** | Uptime | Tiempo sin errores 5xx | % |
| **Capacidad** | Max VUs | Usuarios concurrentes m√°ximos sin degradaci√≥n | usuarios |

### 8.2 M√©tricas de Worker

| M√©trica | Descripci√≥n | Unidad |
|---------|-------------|--------|
| **Videos procesados/min** | Throughput del worker | videos/min |
| **Tiempo medio de procesamiento** | Tiempo promedio por video | segundos |
| **Tiempo por fase** | DB Fetch, S3 Download, FFmpeg, DB Update | segundos |
| **Cola pendiente** | Mensajes en espera en la cola | mensajes |
| **Error rate** | Fallos de procesamiento | % |

### 8.3 M√©tricas de Infraestructura

| Recurso | M√©tricas | Herramienta |
|---------|----------|-------------|
| **CPU** | Utilizaci√≥n %, carga promedio | CloudWatch, docker stats, monitor.sh |
| **Memoria** | Uso MB, porcentaje, swap | CloudWatch, docker stats |
| **Red** | Ancho de banda (NetIO) | CloudWatch, docker stats |
| **Disco** | IO (BlockIO), espacio usado | CloudWatch, docker stats, df -h |
| **Base de datos** | Conexiones activas, latencia de consultas | CloudWatch, logs de RDS |

---

## 9. Configuraci√≥n del Sistema

### 9.1 Arquitectura

```mermaid
graph TD

  A[JMeter<br/>Generador de carga] --> B[API Gateway<br/>HTTPS 443]
  B --> C[Lambda Web<br/>FastAPI Handler]

  C --> D[(Amazon RDS<br/>PostgreSQL)]
  C --> E[S3<br/>Object Storage]

  %% Worker path
  C --> F[SQS<br/>video-processing-queue]

  F --> G1[Lambda Worker<br/>FFmpeg<br/>Worker 1]
  F --> G2[Lambda Worker<br/>FFmpeg<br/>Worker 2]
  F --> G3[Lambda Worker<br/>FFmpeg<br/>Worker 3]

  G1 --> D
  G2 --> D
  G3 --> D

  G1 --> E
  G2 --> E
  G3 --> E

  H[CloudWatch<br/>Logs y M√©tricas]
  H -.-> B
  H -.-> C
  H -.-> F
  H -.-> G1
  H -.-> G2
  H -.-> G3

  style B fill:#4A90E2
  style C fill:#50C878
  style F fill:#FFD700
  style G1 fill:#E27B4A
  style G2 fill:#E27B4A
  style G3 fill:#E27B4A
```

### 9.2 Componentes de Despliegue

La aplicaci√≥n est√° desplegada en AWS con los siguientes componentes:

- **API Gateway:** Punto de entrada p√∫blico, recibe todas las peticiones
- **Lambda:** Servicio de computaci√≥n sin servidor que ejecuta c√≥digo en respuesta a eventos, sin que los usuarios tengan que aprovisionar o administrar servidores.
- **Amazon SQS (video-processing-queue):** Recibe eventos de procesamiento emitidos por la API. Los workers consumen mensajes de aqu√≠
- **Amazon S3:** Almacenamiento en la nube. Guarda los videos subidos y los procesados en carpetas separadas (`/videos/uploaded` y `/videos/processed`)
- **Amazon RDS (PostgreSQL):** Base de datos relacional que guarda toda la informaci√≥n estructurada del sistema
- **Amazon CloudWatch + Alarms:** Recopila m√©tricas

---

### 10.2 Inyecci√≥n de Mensajes en Cola

#### Ejecuci√≥n con Diferentes Configuraciones

```bash
# Ejecutar script de inyecci√≥n
python worker_load_test.py --count 5

# Ejecutar script de inyecci√≥n
python worker_load_test.py --count 10

# Ejecutar script de inyecci√≥n
python worker_load_test.py --count 16

# Repetir con tama√±o 100 MB
```

---