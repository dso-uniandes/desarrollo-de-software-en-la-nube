# üß™ Plan de An√°lisis de Capacidad

## 1. Objetivo General

Evaluar la **capacidad m√°xima** que puede soportar la aplicaci√≥n en sus dos componentes cr√≠ticos:
1. **Capa Web (API HTTP):** endpoint de subida de videos `/api/videos/upload`
2. **Capa Worker:** procesamiento as√≠ncrono de videos con FFmpeg

El prop√≥sito es identificar l√≠mites de **concurrencia, rendimiento y estabilidad**, establecer una l√≠nea base de desempe√±o y proponer acciones de mejora basadas en evidencia.

---

## 2. Objetivos Espec√≠ficos

| N¬∫ | Objetivo | M√©trica asociada |
|----|-----------|------------------|
| 1 | Determinar el n√∫mero m√°ximo de usuarios concurrentes soportados en upload sin degradaci√≥n | p95 ‚â§ 1s, error rate ‚â§ 5% |
| 2 | Medir la capacidad de procesamiento de los workers (videos/minuto) | Throughput y tiempo medio de servicio |
| 3 | Identificar cuellos de botella en CPU, memoria, red o almacenamiento | M√©tricas del host y contenedores |
| 4 | Evaluar la estabilidad bajo carga sostenida y picos repentinos | Desviaci√≥n est√°ndar de latencia y uso de recursos |
| 5 | Validar el tiempo de aceptaci√≥n de archivos de diferentes tama√±os | Tiempo de respuesta para 5 MB, 50 MB, 100 MB |
| 6 | Documentar resultados y recomendaciones de escalabilidad | Informe final con evidencias y gr√°ficos |

---

## 3. Descripci√≥n General

Este plan de pruebas eval√∫a dos componentes cr√≠ticos de la arquitectura:

### 3.1 Capa Web (API HTTP)
- **Endpoint bajo prueba:** `POST /api/videos/upload`
- **Funci√≥n:** Recepci√≥n de archivos multipart/form-data, validaci√≥n, almacenamiento temporal y encolado de tarea
- **Tecnolog√≠a:** FastAPI (Python), almacenamiento S3/local, mensajer√≠a Kafka
- **M√©tricas clave:** Tiempo de aceptaci√≥n, RPS, concurrencia m√°xima, error rate

### 3.2 Capa Worker
- **Funci√≥n:** Procesamiento as√≠ncrono de videos con FFmpeg (branding, trim, concatenaci√≥n)
- **Tecnolog√≠a:** Python, Kafka Consumer, FFmpeg, S3
- **M√©tricas clave:** Videos procesados/minuto, tiempo medio de procesamiento, throughput

Las pruebas se ejecutar√°n en **entorno local** con **Docker Compose**, garantizando un aislamiento controlado y replicable del sistema.

---

## 4. Tipos de Pruebas

| Tipo | Objetivo | Descripci√≥n |
|------|----------|-------------|
| **Capacidad** | Determinar m√°ximo de usuarios concurrentes y RPS sostenido | Incremento progresivo de carga hasta detectar degradaci√≥n |
| **Carga** | Evaluar comportamiento con niveles crecientes de solicitudes | Rampas ascendentes con plateaus de estabilizaci√≥n |
| **Estr√©s** | Analizar respuesta ante sobrecarga extrema | Incremento s√∫bito hasta saturaci√≥n y observar recuperaci√≥n |
| **Picos (Spike)** | Evaluar recuperaci√≥n tras picos repentinos | Carga instant√°nea 10x‚Äì20x durante 20‚Äì30s |
| **Sostenida (Soak)** | Validar estabilidad a largo plazo | 1‚Äì2 horas a carga media para detectar fugas |
| **Escalabilidad Worker** | Validar impacto de aumentar paralelismo | Comparar throughput con 1/2/4 workers |

---

## 5. Criterios de Aceptaci√≥n

### 5.1 Capa Web (Upload)
- ‚úÖ **p95 de latencia ‚â§ 1 segundo** para archivos de hasta 100 MB
- ‚úÖ **Error rate ‚â§ 5%** (excluyendo errores esperados como 400/413)
- ‚úÖ **Sin resets ni timeouts an√≥malos**
- ‚úÖ **CPU del contenedor `storeapi` ‚â§ 85%** sostenido
- ‚úÖ **Tiempo de aceptaci√≥n:**
  - 5 MB: ‚â§ 500 ms
  - 50 MB: ‚â§ 1.5 s
  - 100 MB: ‚â§ 2 s
- ‚úÖ **Validaci√≥n de errores controlados:**
  - 400 para tipos de archivo inv√°lidos
  - 413 para archivos que exceden l√≠mite configurado

### 5.2 Capa Worker
- ‚úÖ **La cola no debe crecer indefinidamente** durante prueba sostenida
- ‚úÖ **Throughput estable** seg√∫n configuraci√≥n de paralelismo
- ‚úÖ **CPU del contenedor `worker` ‚â§ 85%** sostenido
- ‚úÖ **Sin fallos de procesamiento** por timeout o recursos
- ‚úÖ **Tiempo de procesamiento predecible** seg√∫n tama√±o de archivo

---

## 6. Datos de Prueba

### 6.1 Para Capa Web
- **Usuarios simulados:** 5, 50, 100, 200, 300, 400
- **Duraci√≥n por escenario:** 1‚Äì10 minutos
- **Tama√±os de archivo:** 5 MB, 50 MB, 100 MB
- **Formato de archivos:** MP4 (v√°lidos) y archivos inv√°lidos para pruebas de error
- **Credenciales:** Usuario de prueba pre-creado (test@example.com / pass123)

### 6.2 Para Capa Worker
- **Mensajes en cola:** 10 a 500 por ejecuci√≥n
- **Tama√±os de video:** 50 MB, 100 MB
- **Configuraciones de paralelismo:** 1, 2, 4 workers
- **Operaciones FFmpeg:** Intro (2.5s) + Video (max 30s) + Outro (2.5s)

---

## 7. Iteraciones y Repetibilidad

- Cada escenario se repetir√° **m√≠nimo 5 veces** para validar consistencia
- Se calcular√°n: **promedio, desviaci√≥n est√°ndar y percentiles** (p50, p90, p95, p99)
- Se identificar√°n y justificar√°n **valores at√≠picos**
- Se mantendr√° un **baseline** por iteraci√≥n del desarrollo para comparaci√≥n

---

## 8. Configuraci√≥n del Sistema

### 8.1 Arquitectura

```mermaid
graph TD
  A[Newman/Postman<br/>Generador de carga] --> B[Nginx<br/>Reverse Proxy]
  B --> C[StoreAPI<br/>FastAPI]
  C --> D[(PostgreSQL<br/>Base de datos)]
  C --> E[(Redis<br/>Cach√© opcional)]
  C --> F[S3/Local<br/>Almacenamiento]
  C --> G[Kafka<br/>Message Broker]
  G --> H[Worker<br/>FFmpeg Processor]
  H --> F
  H --> D
  
  I[Monitor<br/>Docker Stats] -.-> C
  I -.-> H
  I -.-> G
  
  style C fill:#4A90E2
  style H fill:#E27B4A
  style A fill:#50C878
```

### 8.2 Servicios Docker Compose

| Servicio | Imagen/Tecnolog√≠a | Prop√≥sito |
|----------|-------------------|-----------|
| `nginx` | nginx:latest | Proxy reverso y balanceo de carga |
| `storeapi` | FastAPI (Python 3.11) | API REST para manejo de videos |
| `worker` | Python 3.11 + FFmpeg | Procesamiento as√≠ncrono de videos |
| `anb-database` | PostgreSQL 15 | Persistencia de metadatos |
| `anb-redis` | Redis 7 | Cach√© (opcional) |
| `kafka` | Apache Kafka | Cola de mensajes para tareas |

### 8.3 Host Local (Requisitos M√≠nimos)

- **CPU:** 8 n√∫cleos (m√≠nimo 4 dedicados a Docker)
- **RAM:** 16 GB (m√≠nimo 8 GB disponibles)
- **Disco:** 50 GB libres (para videos y logs)
- **Sistema operativo:** macOS / Linux
- **Docker:** Docker Desktop 4.x o Docker Engine 20.x

---

## 9. Herramientas de Prueba

| Herramienta | Uso | Versi√≥n | Comando de instalaci√≥n |
|-------------|-----|---------|------------------------|
| **Newman** | Ejecuci√≥n automatizada de colecciones Postman | 5.6.3+ | `npm install -g newman` |
| **Postman** | Dise√±o de colecciones y verificaci√≥n manual | √öltima | Descargar de postman.com |
| **Docker Stats** | Monitoreo de recursos de contenedores | Built-in | - |
| **monitor.sh** | Script personalizado para captura de m√©tricas | Custom | Incluido en el proyecto |
| **Python 3.11** | Inyecci√≥n de mensajes en Kafka (worker tests) | 3.11+ | - |
| **jq** | Procesamiento de logs JSON | √öltima | `brew install jq` |

---

## 10. M√©tricas

### 10.1 M√©tricas de Aplicaci√≥n

| Categor√≠a | M√©trica | Descripci√≥n | Unidad |
|-----------|---------|-------------|--------|
| **Latencia** | p50, p90, p95, p99 | Percentiles de tiempo de respuesta | ms |
| **Throughput** | RPS (Requests Per Second) | Solicitudes procesadas por segundo | req/s |
| **Errores** | Error Rate | Porcentaje de respuestas 4xx/5xx | % |
| **Disponibilidad** | Uptime | Tiempo sin errores 5xx | % |
| **Capacidad** | Max VUs | Usuarios concurrentes m√°ximos sin degradaci√≥n | usuarios |

### 10.2 M√©tricas de Worker

| M√©trica | Descripci√≥n | Unidad |
|---------|-------------|--------|
| **Videos procesados/min** | Throughput del worker | videos/min |
| **Tiempo medio de procesamiento** | Tiempo promedio por video | segundos |
| **Tiempo por fase** | DB Fetch, S3 Download, FFmpeg, DB Update | segundos |
| **Cola pendiente** | Mensajes en espera en Kafka | mensajes |
| **Error rate** | Fallos de procesamiento | % |

### 10.3 M√©tricas de Infraestructura

| Recurso | M√©tricas | Herramienta |
|---------|----------|-------------|
| **CPU** | Utilizaci√≥n %, carga promedio | docker stats, monitor.sh |
| **Memoria** | Uso MB, porcentaje, swap | docker stats |
| **Red** | Ancho de banda (NetIO) | docker stats |
| **Disco** | IO (BlockIO), espacio usado | docker stats, df -h |
| **Base de datos** | Conexiones activas, latencia de consultas | Logs de PostgreSQL |

---

## 11. Escenarios de Prueba

### 11.1 Escenario 1: Capacidad de la Capa Web (Upload)

**Objetivo:** Determinar el m√°ximo de usuarios concurrentes y RPS que soporta `POST /api/videos/upload` cumpliendo SLOs.

**Estrategia:**
1. **Smoke Test:** 5 VUs durante 1 minuto (validaci√≥n b√°sica)
2. **Ramp Test:** Incremento gradual 0 ‚Üí X VUs en 3 minutos, mantener 5 minutos
3. **Capacity Test:** Encontrar X m√°ximo donde p95 ‚â§ 1s y error rate ‚â§ 5%
4. **Sustained Test:** 5 minutos al 80% de X para validar estabilidad

**Configuraci√≥n Newman:**
```bash
# Smoke test (5 usuarios, 60 iteraciones total)
newman run postman/collection.json \
  -e postman/environment.json \
  --iteration-count 60 \
  --delay-request 1000 \
  -r cli,html \
  --reporter-html-export postman/report_smoke.html

# Ramp test (incremento gradual simulado con m√∫ltiples ejecuciones)
for users in 50 100 150 200 250 300; do
  echo "Testing with $users users..."
  newman run postman/collection.json \
    -e postman/environment.json \
    --iteration-count $users \
    --delay-request 200 \
    -r cli,html \
    --reporter-html-export postman/report_${users}users.html
  sleep 30  # pausa entre escalones
done
```

**Criterios de √©xito:**
- ‚úÖ p95 ‚â§ 1s
- ‚úÖ Error rate ‚â§ 5% (excluyendo 400/413 esperados)
- ‚úÖ CPU API ‚â§ 85%
- ‚úÖ Sin resets/timeouts an√≥malos

**Salidas esperadas:**
- Curva: Usuarios concurrentes vs. p95 latencia
- Gr√°fico: RPS vs. Error rate
- Identificaci√≥n de capacidad m√°xima
- Reporte HTML de Newman con estad√≠sticas detalladas

---

### 11.2 Escenario 2: Rendimiento de la Capa Worker

**Objetivo:** Medir videos/min procesados a distintos tama√±os y niveles de paralelismo.

**Estrategia:**
1. **Bypass de la capa web:** Inyectar mensajes directamente en Kafka topic `video_tasks`
2. **Variables experimentales:**
   - Tama√±os: 50 MB, 100 MB
   - Paralelismo: 1, 2, 4 workers
3. **Medici√≥n:** Saturaci√≥n (aumentar tareas) y sostenida (mantener backlog fijo)

**Inyecci√≥n de mensajes (Python script):**
```python
# worker_load_test.py
from confluent_kafka import Producer
import json
import time

producer = Producer({'bootstrap.servers': 'localhost:9092'})

# Inyectar 100 tareas
for i in range(100):
    message = {
        'task_id': f'test-task-{i}',
        'video_id': 1,  # ID de video existente en DB
    }
    producer.produce('video_tasks', json.dumps(message))
    if i % 10 == 0:
        print(f'Enqueued {i} tasks...')
        time.sleep(1)  # control de ritmo

producer.flush()
print('All tasks enqueued!')
```

**Ejecuci√≥n:**
```bash
# Con 1 worker (default)
docker-compose up -d worker

# Con 2 workers
docker-compose up -d --scale worker=2

# Con 4 workers
docker-compose up -d --scale worker=4

# Inyectar carga
python worker_load_test.py

# Monitorear procesamiento
docker logs -f worker | grep "TOTAL TASK TIME"
```

**M√©tricas a calcular:**
- Videos procesados/minuto = (Total videos / Tiempo total en min)
- Tiempo medio de servicio = Promedio de "TOTAL TASK TIME"
- Descomposici√≥n: DB Fetch, S3 Download, FFmpeg, DB Update
- Pendiente de la cola = Mensajes encolados - Mensajes procesados

**Criterios de √©xito:**
- ‚úÖ Capacidad nominal estable (throughput constante)
- ‚úÖ Cola no crece indefinidamente (pendiente ‚âà 0 en sostenidas)
- ‚úÖ CPU worker ‚â§ 85%
- ‚úÖ Sin errores de procesamiento

**Salidas esperadas:**
- Tabla: Capacidad por configuraci√≥n (1/2/4 workers) y tama√±o (50/100 MB)
- Gr√°fico: Throughput vs. Paralelismo
- Identificaci√≥n de cuellos de botella (CPU, IO, S3, DB)

---

## 12. Ejecuci√≥n de Pruebas con Makefile

El proyecto incluye un `Makefile` con comandos automatizados para facilitar la ejecuci√≥n de pruebas.

### 12.1 Comandos Disponibles

```bash
# Levantar toda la infraestructura
make up

# Ver estado de los contenedores
make ps

# Ejecutar colecci√≥n de Newman (pruebas de upload)
make newman

# Ejecutar con monitoreo de recursos
make newman-with-monitor

# Iniciar monitoreo manual
make monitor-start

# Detener monitoreo manual
make monitor-stop

# Apagar todo y limpiar
make down
```

### 12.2 Flujo de Ejecuci√≥n Completo

**Paso 1: Preparaci√≥n del entorno**
```bash
# 1. Levantar servicios
make up

# 2. Verificar que todos los servicios est√©n corriendo
make ps

# Salida esperada:
# NAME                 STATUS              PORTS
# storeapi             Up 30 seconds       0.0.0.0:8000->8000/tcp
# worker               Up 30 seconds       
# nginx                Up 30 seconds       0.0.0.0:80->80/tcp
# anb-database         Up 30 seconds       5432/tcp
# kafka                Up 30 seconds       9092/tcp
# anb-redis            Up 30 seconds       6379/tcp

# 3. Verificar logs (opcional)
docker logs storeapi --tail 50
docker logs worker --tail 50
```

**Paso 2: Crear usuario de prueba**
```bash
# Desde Postman o curl
curl -X POST http://localhost/api/auth/signup \
  -H "Content-Type: application/json" \
  -d '{
    "email": "test@example.com",
    "password": "pass123"
  }'

# Verificar creaci√≥n (debe retornar 201)
```

**Paso 3: Ejecutar pruebas con monitoreo**
```bash
# Ejecuci√≥n automatizada con captura de m√©tricas
make newman-with-monitor

# Esto ejecuta:
# 1. Inicia monitor.sh en background (captura CPU/Mem cada 1s)
# 2. Ejecuta newman con la colecci√≥n
# 3. Detiene el monitor
# 4. Genera reporte HTML en postman/report.html
```

**Paso 4: An√°lisis de resultados**

**Reporte de Newman:**
```bash
# Abrir reporte HTML
open postman/report.html  # macOS
xdg-open postman/report.html  # Linux

# Contenido del reporte:
# - Total de requests ejecutados
# - Distribuci√≥n de c√≥digos de respuesta (200, 201, 400, 413)
# - Tiempos de respuesta: min, max, avg, p95
# - Tests pasados/fallados
# - Timeline de ejecuci√≥n
```

**Paso 5: Monitoreo interactivo**

Durante las pruebas, puedes usar el script `monitor.sh` para observar recursos en tiempo real:

```bash
# Modo interactivo con men√∫
./monitor.sh

# Opciones:
# 1) Show real-time stats (streaming)     <- Ver recursos en vivo
# 2) Show snapshot (one-time)              <- Captura puntual
# 3) Show worker processing times          <- Logs de worker
# 4) Show all (snapshot + worker times)    <- Todo junto
# 5) Exit

# Modo directo (sin men√∫)
./monitor.sh --stream          # Streaming en tiempo real
./monitor.sh --snapshot        # Captura √∫nica
./monitor.sh --worker          # Solo logs de worker
```

### 12.3 Resultados Esperados por Escenario

**Escenario 1: Upload con 50 usuarios concurrentes**
```
Archivo: postman/report_50users.html

M√©tricas esperadas:
‚îú‚îÄ Total requests: 50
‚îú‚îÄ Success rate: 95-100%
‚îú‚îÄ p95 latency: 500-800ms (5MB), 1-1.5s (50MB)
‚îú‚îÄ C√≥digos HTTP:
‚îÇ  ‚îú‚îÄ 201 Created: 47-50 (95-100%)
‚îÇ  ‚îú‚îÄ 400 Bad Request: 0-2 (0-4%)
‚îÇ  ‚îî‚îÄ 413 Payload Too Large: 0-1 (0-2%)
‚îî‚îÄ Duration: ~2-3 minutos

Recursos (cpu_stats_newman.log):
‚îú‚îÄ storeapi CPU: 40-60% promedio, picos de 75%
‚îú‚îÄ worker CPU: 15-25% (si hay procesamiento concurrente)
‚îú‚îÄ nginx CPU: 5-10%
‚îî‚îÄ Database CPU: 10-15%
```

**Escenario 2: Upload con 200 usuarios concurrentes**
```
Archivo: postman/report_200users.html

M√©tricas esperadas:
‚îú‚îÄ Total requests: 200
‚îú‚îÄ Success rate: 90-95%
‚îú‚îÄ p95 latency: 900-1200ms (puede degradarse)
‚îú‚îÄ C√≥digos HTTP:
‚îÇ  ‚îú‚îÄ 201 Created: 180-190 (90-95%)
‚îÇ  ‚îú‚îÄ 400/413: 5-10 (2.5-5%)
‚îÇ  ‚îî‚îÄ 500/502/503: 0-10 (0-5%)
‚îî‚îÄ Duration: ~5-8 minutos

Recursos:
‚îú‚îÄ storeapi CPU: 70-85% promedio, picos de >90% ‚ö†Ô∏è
‚îú‚îÄ worker CPU: 30-50%
‚îú‚îÄ Posibles cuellos de botella:
‚îÇ  ‚îú‚îÄ CPU de storeapi (considerar escalado)
‚îÇ  ‚îú‚îÄ Ancho de banda de red
‚îÇ  ‚îî‚îÄ Latencia de escritura en S3/local
```

**Escenario 3: Worker con 100 videos (50MB, 2 workers)**
```
Logs: docker logs worker

M√©tricas esperadas:
‚îú‚îÄ Videos procesados: 100
‚îú‚îÄ Throughput: 3-5 videos/min por worker (6-10 total)
‚îú‚îÄ Tiempo promedio: 12-18 segundos/video
‚îú‚îÄ Descomposici√≥n:
‚îÇ  ‚îú‚îÄ DB Fetch: 0.1-0.2s (despreciable)
‚îÇ  ‚îú‚îÄ S3 Download: 2-4s (dependiente de red)
‚îÇ  ‚îú‚îÄ FFmpeg: 10-14s (80-85% del tiempo)
‚îÇ  ‚îî‚îÄ DB Update: 0.3-0.6s
‚îî‚îÄ Duraci√≥n total: 10-17 minutos

Recursos:
‚îú‚îÄ worker-1 CPU: 70-85%
‚îú‚îÄ worker-2 CPU: 70-85%
‚îú‚îÄ Cuello de botella principal: FFmpeg (CPU-bound)
‚îî‚îÄ Recomendaci√≥n: Escalar a 4 workers puede duplicar throughput
```

---

## 13. Riesgos y Limitaciones

### 13.1 Limitaciones del Entorno Local

- ‚ö†Ô∏è El hardware local puede diferir significativamente de un entorno productivo (CPU, IO, red)
- ‚ö†Ô∏è Docker Desktop en macOS/Windows introduce sobrecarga adicional comparado con Linux nativo
- ‚ö†Ô∏è Compartir recursos con otros procesos del sistema puede afectar resultados
- ‚ö†Ô∏è Almacenamiento local es m√°s r√°pido que S3 real (puede enmascarar latencias)

### 13.2 Riesgos Identificados

| Riesgo | Impacto | Mitigaci√≥n |
|--------|---------|------------|
| Hardware insuficiente causa fallos prematuros | Alto | Documentar specs y ajustar expectativas |
| Variabilidad entre ejecuciones por procesos background | Medio | Ejecutar 5+ iteraciones y promediar |
| Agotamiento de disco por videos acumulados | Medio | Limpiar `videos/` entre pruebas |
| Timeout de Kafka o DB por recursos | Alto | Monitorear logs y ajustar configuraciones |
| Newman no genera suficiente concurrencia | Medio | Ejecutar m√∫ltiples instancias en paralelo |