# üß™ Plan de An√°lisis de Capacidad

## 1. Objetivo General

Evaluar la **capacidad m√°xima** que puede soportar la aplicaci√≥n en sus dos componentes cr√≠ticos:
1. **Capa Web (API HTTP):** endpoint de subida de videos `/api/videos/upload`
2. **Capa Worker:** procesamiento as√≠ncrono de videos con FFmpeg

El prop√≥sito es identificar l√≠mites de **concurrencia, rendimiento y estabilidad**, establecer una l√≠nea base de desempe√±o y proponer acciones de mejora basadas en evidencia.

---

## 2. Objetivos Espec√≠ficos

| N¬∫ | Objetivo | M√©trica asociada |
|----|-----------|------------------|
| 1 | Determinar el n√∫mero m√°ximo de usuarios concurrentes soportados en upload sin degradaci√≥n | p95 ‚â§ 1s, error rate ‚â§ 5% |
| 2 | Medir la capacidad de procesamiento de los workers (videos/minuto) | Throughput y tiempo medio de servicio |
| 3 | Identificar cuellos de botella en CPU, memoria, red o almacenamiento | M√©tricas del host y contenedores |
| 4 | Evaluar la estabilidad bajo carga sostenida y picos repentinos | Desviaci√≥n est√°ndar de latencia y uso de recursos |
| 5 | Validar el tiempo de aceptaci√≥n de archivos de diferentes tama√±os | Tiempo de respuesta para 5 MB, 50 MB, 100 MB |
| 6 | Documentar resultados y recomendaciones de escalabilidad | Informe final con evidencias y gr√°ficos |

---

## 3. Descripci√≥n General

Este plan de pruebas eval√∫a dos componentes cr√≠ticos de la arquitectura:

### 3.1 Capa Web (API HTTP)
- **Endpoint bajo prueba:** `POST /api/videos/upload`
- **Funci√≥n:** Recepci√≥n de archivos multipart/form-data, validaci√≥n, almacenamiento temporal y encolado de tarea
- **Tecnolog√≠a:** FastAPI (Python), almacenamiento S3/local, mensajer√≠a Kafka
- **M√©tricas clave:** Tiempo de aceptaci√≥n, RPS, concurrencia m√°xima, error rate

### 3.2 Capa Worker
- **Funci√≥n:** Procesamiento as√≠ncrono de videos con FFmpeg (branding, trim, concatenaci√≥n)
- **Tecnolog√≠a:** Python, Kafka Consumer, FFmpeg, S3
- **M√©tricas clave:** Videos procesados/minuto, tiempo medio de procesamiento, throughput

Las pruebas se ejecutar√°n en **entorno local** con **Docker Compose**, garantizando un aislamiento controlado y replicable del sistema.

---

## 4. Tipos de Pruebas

| Tipo | Objetivo | Descripci√≥n |
|------|----------|-------------|
| **Capacidad** | Determinar m√°ximo de usuarios concurrentes y RPS sostenido | Incremento progresivo de carga hasta detectar degradaci√≥n |
| **Carga** | Evaluar comportamiento con niveles crecientes de solicitudes | Rampas ascendentes con plateaus de estabilizaci√≥n |
| **Estr√©s** | Analizar respuesta ante sobrecarga extrema | Incremento s√∫bito hasta saturaci√≥n y observar recuperaci√≥n |
| **Picos (Spike)** | Evaluar recuperaci√≥n tras picos repentinos | Carga instant√°nea 10x‚Äì20x durante 20‚Äì30s |
| **Sostenida (Soak)** | Validar estabilidad a largo plazo | 1‚Äì2 horas a carga media para detectar fugas |
| **Escalabilidad Worker** | Validar impacto de aumentar paralelismo | Comparar throughput con 1/2/4 workers |

---

## 5. Criterios de Aceptaci√≥n

### 5.1 Capa Web (Upload)
- ‚úÖ **p95 de latencia ‚â§ 1 segundo** para archivos de hasta 100 MB
- ‚úÖ **Error rate ‚â§ 5%** (excluyendo errores esperados como 400/413)
- ‚úÖ **Sin resets ni timeouts an√≥malos**
- ‚úÖ **CPU del contenedor `storeapi` ‚â§ 85%** sostenido
- ‚úÖ **Tiempo de aceptaci√≥n:**
  - 5 MB: ‚â§ 500 ms
  - 50 MB: ‚â§ 1.5 s
  - 100 MB: ‚â§ 2 s
- ‚úÖ **Validaci√≥n de errores controlados:**
  - 400 para tipos de archivo inv√°lidos
  - 413 para archivos que exceden l√≠mite configurado

### 5.2 Capa Worker
- ‚úÖ **La cola no debe crecer indefinidamente** durante prueba sostenida
- ‚úÖ **Throughput estable** seg√∫n configuraci√≥n de paralelismo
- ‚úÖ **CPU del contenedor `worker` ‚â§ 85%** sostenido
- ‚úÖ **Sin fallos de procesamiento** por timeout o recursos
- ‚úÖ **Tiempo de procesamiento predecible** seg√∫n tama√±o de archivo

---

## 6. Datos de Prueba

### 6.1 Para Capa Web
- **Usuarios simulados:** 5, 50, 100, 200, 300, 400
- **Duraci√≥n por escenario:** 1‚Äì10 minutos
- **Tama√±os de archivo:** 5 MB, 50 MB, 100 MB
- **Formato de archivos:** MP4 (v√°lidos) y archivos inv√°lidos para pruebas de error
- **Credenciales:** Usuario de prueba pre-creado (test@example.com / pass123)

### 6.2 Para Capa Worker
- **Mensajes en cola:** 10 a 500 por ejecuci√≥n
- **Tama√±os de video:** 50 MB, 100 MB
- **Configuraciones de paralelismo:** 1, 2, 4 workers
- **Operaciones FFmpeg:** Intro (2.5s) + Video (max 30s) + Outro (2.5s)

---

## 7. Iteraciones y Repetibilidad

- Cada escenario se repetir√° **m√≠nimo 5 veces** para validar consistencia
- Se calcular√°n: **promedio, desviaci√≥n est√°ndar y percentiles** (p50, p90, p95, p99)
- Se identificar√°n y justificar√°n **valores at√≠picos**
- Se mantendr√° un **baseline** por iteraci√≥n del desarrollo para comparaci√≥n

---

## 8. Configuraci√≥n del Sistema

### 8.1 Arquitectura

```mermaid
graph TD
  A[Newman/Postman<br/>Generador de carga] --> B[Nginx<br/>Reverse Proxy]
  B --> C[StoreAPI<br/>FastAPI]
  C --> D[(PostgreSQL<br/>Base de datos)]
  C --> E[(Redis<br/>Cach√© opcional)]
  C --> F[S3/Local<br/>Almacenamiento]
  C --> G[Kafka<br/>Message Broker]
  G --> H[Worker<br/>FFmpeg Processor]
  H --> F
  H --> D
  
  I[Monitor<br/>Docker Stats] -.-> C
  I -.-> H
  I -.-> G
  
  style C fill:#4A90E2
  style H fill:#E27B4A
  style A fill:#50C878
```

### 8.2 Servicios Docker Compose

| Servicio | Imagen/Tecnolog√≠a | Prop√≥sito |
|----------|-------------------|-----------|
| `nginx` | nginx:latest | Proxy reverso y balanceo de carga |
| `storeapi` | FastAPI (Python 3.11) | API REST para manejo de videos |
| `worker` | Python 3.11 + FFmpeg | Procesamiento as√≠ncrono de videos |
| `anb-database` | PostgreSQL 15 | Persistencia de metadatos |
| `anb-redis` | Redis 7 | Cach√© (opcional) |
| `kafka` | Apache Kafka | Cola de mensajes para tareas |

### 8.3 Host Local (Requisitos M√≠nimos)

- **CPU:** 8 n√∫cleos (m√≠nimo 4 dedicados a Docker)
- **RAM:** 16 GB (m√≠nimo 8 GB disponibles)
- **Disco:** 50 GB libres (para videos y logs)
- **Sistema operativo:** macOS / Linux
- **Docker:** Docker Desktop 4.x o Docker Engine 20.x

---

## 9. Herramientas de Prueba

| Herramienta | Uso | Versi√≥n | Comando de instalaci√≥n |
|-------------|-----|---------|------------------------|
| **Newman** | Ejecuci√≥n automatizada de colecciones Postman | 5.6.3+ | `npm install -g newman` |
| **Postman** | Dise√±o de colecciones y verificaci√≥n manual | √öltima | Descargar de postman.com |
| **Docker Stats** | Monitoreo de recursos de contenedores | Built-in | - |
| **monitor.sh** | Script personalizado para captura de m√©tricas | Custom | Incluido en el proyecto |
| **Python 3.11** | Inyecci√≥n de mensajes en Kafka (worker tests) | 3.11+ | - |
| **jq** | Procesamiento de logs JSON | √öltima | `brew install jq` |

---

## 10. M√©tricas

### 10.1 M√©tricas de Aplicaci√≥n

| Categor√≠a | M√©trica | Descripci√≥n | Unidad |
|-----------|---------|-------------|--------|
| **Latencia** | p50, p90, p95, p99 | Percentiles de tiempo de respuesta | ms |
| **Throughput** | RPS (Requests Per Second) | Solicitudes procesadas por segundo | req/s |
| **Errores** | Error Rate | Porcentaje de respuestas 4xx/5xx | % |
| **Disponibilidad** | Uptime | Tiempo sin errores 5xx | % |
| **Capacidad** | Max VUs | Usuarios concurrentes m√°ximos sin degradaci√≥n | usuarios |

### 10.2 M√©tricas de Worker

| M√©trica | Descripci√≥n | Unidad |
|---------|-------------|--------|
| **Videos procesados/min** | Throughput del worker | videos/min |
| **Tiempo medio de procesamiento** | Tiempo promedio por video | segundos |
| **Tiempo por fase** | DB Fetch, S3 Download, FFmpeg, DB Update | segundos |
| **Cola pendiente** | Mensajes en espera en Kafka | mensajes |
| **Error rate** | Fallos de procesamiento | % |

### 10.3 M√©tricas de Infraestructura

| Recurso | M√©tricas | Herramienta |
|---------|----------|-------------|
| **CPU** | Utilizaci√≥n %, carga promedio | docker stats, monitor.sh |
| **Memoria** | Uso MB, porcentaje, swap | docker stats |
| **Red** | Ancho de banda (NetIO) | docker stats |
| **Disco** | IO (BlockIO), espacio usado | docker stats, df -h |
| **Base de datos** | Conexiones activas, latencia de consultas | Logs de PostgreSQL |

---

## 11. Escenarios de Prueba

### 11.1 Escenario 1: Capacidad de la Capa Web (Upload)

**Objetivo:** Determinar el m√°ximo de usuarios concurrentes y RPS que soporta `POST /api/videos/upload` cumpliendo SLOs.

**Estrategia:**
1. **Smoke Test:** 5 VUs durante 1 minuto (validaci√≥n b√°sica)
2. **Ramp Test:** Incremento gradual 0 ‚Üí X VUs en 3 minutos, mantener 5 minutos
3. **Capacity Test:** Encontrar X m√°ximo donde p95 ‚â§ 1s y error rate ‚â§ 5%
4. **Sustained Test:** 5 minutos al 80% de X para validar estabilidad

**Configuraci√≥n Newman:**
```bash
# Smoke test (5 usuarios, 60 iteraciones total)
newman run postman/collection.json \
  -e postman/environment.json \
  --iteration-count 60 \
  --delay-request 1000 \
  -r cli,html \
  --reporter-html-export postman/report_smoke.html

# Ramp test (incremento gradual simulado con m√∫ltiples ejecuciones)
for users in 50 100 150 200 250 300; do
  echo "Testing with $users users..."
  newman run postman/collection.json \
    -e postman/environment.json \
    --iteration-count $users \
    --delay-request 200 \
    -r cli,html \
    --reporter-html-export postman/report_${users}users.html
  sleep 30  # pausa entre escalones
done
```

**Criterios de √©xito:**
- ‚úÖ p95 ‚â§ 1s
- ‚úÖ Error rate ‚â§ 5% (excluyendo 400/413 esperados)
- ‚úÖ CPU API ‚â§ 85%
- ‚úÖ Sin resets/timeouts an√≥malos

**Salidas esperadas:**
- Curva: Usuarios concurrentes vs. p95 latencia
- Gr√°fico: RPS vs. Error rate
- Identificaci√≥n de capacidad m√°xima
- Reporte HTML de Newman con estad√≠sticas detalladas

---

### 11.2 Escenario 2: Rendimiento de la Capa Worker

**Objetivo:** Medir videos/min procesados a distintos tama√±os y niveles de paralelismo.

**Estrategia:**
1. **Bypass de la capa web:** Inyectar mensajes directamente en Kafka topic `video_tasks`
2. **Variables experimentales:**
   - Tama√±os: 50 MB, 100 MB
   - Paralelismo: 1, 2, 4 workers
3. **Medici√≥n:** Saturaci√≥n (aumentar tareas) y sostenida (mantener backlog fijo)

**Inyecci√≥n de mensajes (Python script):**
```python
# worker_load_test.py
from confluent_kafka import Producer
import json
import time

producer = Producer({'bootstrap.servers': 'localhost:9092'})

# Inyectar 100 tareas
for i in range(100):
    message = {
        'task_id': f'test-task-{i}',
        'video_id': 1,  # ID de video existente en DB
    }
    producer.produce('video_tasks', json.dumps(message))
    if i % 10 == 0:
        print(f'Enqueued {i} tasks...')
        time.sleep(1)  # control de ritmo

producer.flush()
print('All tasks enqueued!')
```

**Ejecuci√≥n:**
```bash
# Con 1 worker (default)
docker-compose up -d worker

# Con 2 workers
docker-compose up -d --scale worker=2

# Con 4 workers
docker-compose up -d --scale worker=4

# Inyectar carga
python worker_load_test.py

# Monitorear procesamiento
docker logs -f worker | grep "TOTAL TASK TIME"
```

**M√©tricas a calcular:**
- Videos procesados/minuto = (Total videos / Tiempo total en min)
- Tiempo medio de servicio = Promedio de "TOTAL TASK TIME"
- Descomposici√≥n: DB Fetch, S3 Download, FFmpeg, DB Update
- Pendiente de la cola = Mensajes encolados - Mensajes procesados

**Criterios de √©xito:**
- ‚úÖ Capacidad nominal estable (throughput constante)
- ‚úÖ Cola no crece indefinidamente (pendiente ‚âà 0 en sostenidas)
- ‚úÖ CPU worker ‚â§ 85%
- ‚úÖ Sin errores de procesamiento

**Salidas esperadas:**
- Tabla: Capacidad por configuraci√≥n (1/2/4 workers) y tama√±o (50/100 MB)
- Gr√°fico: Throughput vs. Paralelismo
- Identificaci√≥n de cuellos de botella (CPU, IO, S3, DB)

---

## 12. Ejecuci√≥n de Pruebas con Makefile

El proyecto incluye un `Makefile` en la carpeta `capacity-planning/` con comandos automatizados para facilitar la ejecuci√≥n de pruebas.

**Importante**: Todos los comandos `make` deben ejecutarse desde la ra√≠z del proyecto usando:
```bash
make -C ./capacity-planning/ <comando>
```

### 12.1 Comandos Disponibles

#### Gesti√≥n de Infraestructura
```bash
# Levantar toda la infraestructura
make -C ./capacity-planning/ up

# Ver estado de los contenedores
make -C ./capacity-planning/ ps

# Ver logs en tiempo real
make -C ./capacity-planning/ logs

# Apagar todo y limpiar
make -C ./capacity-planning/ down
```

#### Monitoreo de Recursos
```bash
# Iniciar monitoreo (containers + worker timing)
make -C ./capacity-planning/ monitor-start

# Detener monitoreo y calcular estad√≠sticas
make -C ./capacity-planning/ monitor-stop

# Forzar detenci√≥n de monitores (si quedan colgados)
make -C ./capacity-planning/ kill-monitors

# Ver estad√≠sticas generadas
make -C ./capacity-planning/ view-stats

# Calcular estad√≠sticas manualmente
make -C ./capacity-planning/ calculate-stats

# Ver resultados de √∫ltima ejecuci√≥n
make -C ./capacity-planning/ show-results
```

#### Ejecuci√≥n de Tests
```bash
# Test b√°sico con Newman
make -C ./capacity-planning/ newman

# Smoke Test - 5 usuarios, 1 minuto (validaci√≥n b√°sica)
make -C ./capacity-planning/ test-smoke

# Capacity Test - Incremental (50, 100, 150, 200, 250, 300 usuarios)
make -C ./capacity-planning/ test-capacity

# Ramp Test - Rampa gradual 0‚Üí300 usuarios
make -C ./capacity-planning/ test-ramp

# Sustained Test - Carga sostenida por 10 minutos
make -C ./capacity-planning/ test-sustained

# Stress Test - Sobrecarga hasta fallo
make -C ./capacity-planning/ test-stress

# Spike Test - Picos repentinos de carga
make -C ./capacity-planning/ test-spike
```

#### Utilidades
```bash
# Limpiar archivos temporales
make -C ./capacity-planning/ clean

# Ver ayuda con todos los comandos
make -C ./capacity-planning/ help
```

### 12.2 Flujo de Ejecuci√≥n Completo

#### Paso 1: Preparaci√≥n del entorno

```bash
# 1. Levantar servicios
make -C ./capacity-planning/ up

# 2. Verificar que todos los servicios est√©n corriendo
make -C ./capacity-planning/ ps

# Salida esperada:
# NAME                 STATUS              PORTS
# storeapi             Up 30 seconds       0.0.0.0:8000->8000/tcp
# worker               Up 30 seconds       
# nginx                Up 30 seconds       0.0.0.0:80->80/tcp
# anb-database         Up 30 seconds       5432/tcp
# kafka                Up 30 seconds       9092/tcp
# anb-redis            Up 30 seconds       6379/tcp

# 3. Verificar logs (opcional)
make -C ./capacity-planning/ logs
```

#### Paso 2: Crear usuario de prueba

```bash
# Desde Postman o curl
curl -X POST http://localhost/api/auth/signup \
  -H "Content-Type: application/json" \
  -d '{
    "email": "test@example.com",
    "password": "pass123"
  }'

# Verificar creaci√≥n (debe retornar 201)
```

#### Paso 3: Ejecutar pruebas seg√∫n escenario

##### Opci√≥n A: Smoke Test (validaci√≥n r√°pida)

```bash
# Ejecutar smoke test (5 usuarios, 1 minuto)
make -C ./capacity-planning/ test-smoke

# Esto ejecuta autom√°ticamente:
# 1. Inicia monitores (containers + worker timing)
# 2. Ejecuta newman con 5 iteraciones
# 3. Espera a que worker termine de procesar
# 4. Detiene monitores y calcula estad√≠sticas
# 5. Genera reportes HTML y CSV
```

##### Opci√≥n B: Capacity Test (encontrar l√≠mite)

```bash
# Ejecutar capacity test (50‚Üí300 usuarios incrementales)
make -C ./capacity-planning/ test-capacity

# Esto ejecuta:
# - 6 iteraciones con 50, 100, 150, 200, 250, 300 usuarios
# - Monitoreo continuo durante todas las iteraciones
# - Pausa de 30s entre cada escal√≥n
# - Espera a que worker termine todos los videos
# - Genera estad√≠sticas consolidadas al final
```

##### Opci√≥n C: Sustained Test (estabilidad)

```bash
# Ejecutar sustained test (10 minutos de carga constante)
make -C ./capacity-planning/ test-sustained

# Eval√∫a:
# - Estabilidad a largo plazo
# - Posibles memory leaks
# - Degradaci√≥n progresiva de rendimiento
```

##### Opci√≥n D: Stress Test (hasta el fallo)

```bash
# Ejecutar stress test (carga progresiva hasta saturaci√≥n)
make -C ./capacity-planning/ test-stress

# Identifica:
# - Punto de quiebre del sistema
# - Comportamiento ante sobrecarga
# - Capacidad de recuperaci√≥n
```

##### Opci√≥n E: Spike Test (picos repentinos)

```bash
# Ejecutar spike test (picos instant√°neos)
make -C ./capacity-planning/ test-spike

# Eval√∫a:
# - Respuesta ante tr√°fico s√∫bito
# - Auto-scaling (si aplica)
# - Recuperaci√≥n tras el pico
```

#### Paso 4: An√°lisis de resultados

##### Ver estad√≠sticas generadas

```bash
# Mostrar estad√≠sticas en consola
make -C ./capacity-planning/ view-stats

# Salida esperada:
# ============================================
# Container Resource Statistics
# ============================================
# 
# storeapi:
#   CPU: min=25.5%, max=84.2%, avg=58.3%, p95=79.1%
#   Memory: min=245MB, max=512MB, avg=385MB
# 
# worker:
#   CPU: min=15.3%, max=92.1%, avg=67.8%, p95=88.5%
#   Memory: min=180MB, max=420MB, avg=298MB
# 
# ============================================
# Worker Timing Statistics
# ============================================
# 
# Total tasks processed: 150
# Total time: avg=12.5s, p95=18.2s
# FFmpeg time: avg=10.8s, p95=16.1s
# DB operations: avg=0.9s
# S3 operations: avg=0.8s
```

##### Abrir reportes HTML

```bash
# Ver reportes generados
make -C ./capacity-planning/ show-results

# Los reportes se encuentran en:
# capacity-planning/postman/results/
# ‚îú‚îÄ‚îÄ report_smoke_20251019_154230.html
# ‚îú‚îÄ‚îÄ report_capacity_20251019_154230.html
# ‚îú‚îÄ‚îÄ container_stats_20251019_154230.csv
# ‚îú‚îÄ‚îÄ worker_timing_20251019_154230.csv
# ‚îî‚îÄ‚îÄ summary_20251019_154230.csv

# Abrir en navegador (macOS)
open capacity-planning/postman/results/report_smoke_*.html

# Abrir en navegador (Linux)
xdg-open capacity-planning/postman/results/report_smoke_*.html
```

##### Archivos CSV generados

1. **container_stats_TIMESTAMP.csv**: M√©tricas de recursos por contenedor
   - Timestamp, Container, CPU%, Memory MB, Memory%, NetIO, BlockIO

2. **worker_timing_TIMESTAMP.csv**: Tiempos de procesamiento por tarea
   - Timestamp, task_id, video_id, total_time, db_fetch, s3_download, ffmpeg, db_update

3. **summary_TIMESTAMP.csv**: Estad√≠sticas consolidadas
   - Min, Max, Avg, Median, StdDev, P95 para cada m√©trica

#### Paso 5: Monitoreo manual (opcional)

Si necesitas observar en tiempo real sin ejecutar tests:

```bash
# Iniciar monitores manualmente
make -C ./capacity-planning/ monitor-start

# ... ejecutar operaciones manualmente ...

# Detener monitores y calcular estad√≠sticas
make -C ./capacity-planning/ monitor-stop
```

#### Paso 6: Limpieza

```bash
# Detener servicios
make -C ./capacity-planning/ down

# Limpiar archivos temporales (opcional)
make -C ./capacity-planning/ clean
```

### 12.3 Resultados Esperados por Escenario

#### Escenario 1: Smoke Test (5 usuarios, 1 minuto)

**Prop√≥sito:** Validaci√≥n b√°sica del sistema

```text
Archivo: postman/results/report_smoke_TIMESTAMP.html

M√©tricas esperadas:
‚îú‚îÄ Total requests: 5
‚îú‚îÄ Success rate: 100%
‚îú‚îÄ p95 latency: 300-600ms
‚îú‚îÄ C√≥digos HTTP:
‚îÇ  ‚îî‚îÄ 201 Created: 5 (100%)
‚îî‚îÄ Duration: ~1-2 minutos

Recursos (container_stats_TIMESTAMP.csv):
‚îú‚îÄ storeapi CPU: 15-30% promedio
‚îú‚îÄ worker CPU: 10-20% (procesamiento ligero)
‚îú‚îÄ nginx CPU: 5-10%
‚îî‚îÄ Database CPU: 5-10%

Worker timing (worker_timing_TIMESTAMP.csv):
‚îú‚îÄ Tasks procesados: 5
‚îú‚îÄ Total time avg: 8-12s
‚îú‚îÄ FFmpeg avg: 7-10s (mayor componente)
‚îî‚îÄ S3 operations: 0.5-1s
```

**Interpretaci√≥n:** Si el smoke test falla, hay problemas b√°sicos de configuraci√≥n.

#### Escenario 2: Capacity Test (50‚Üí300 usuarios incremental)

**Prop√≥sito:** Encontrar el punto de quiebre del sistema

```text
Archivos: 
- postman/results/report_capacity_TIMESTAMP.html
- postman/results/summary_TIMESTAMP.csv

M√©tricas esperadas por escal√≥n:

50 usuarios:
‚îú‚îÄ Success rate: 98-100%
‚îú‚îÄ p95 latency: 500-800ms
‚îî‚îÄ storeapi CPU: 40-55%

100 usuarios:
‚îú‚îÄ Success rate: 95-98%
‚îú‚îÄ p95 latency: 700-1000ms
‚îî‚îÄ storeapi CPU: 55-70%

150 usuarios:
‚îú‚îÄ Success rate: 90-95%
‚îú‚îÄ p95 latency: 900-1200ms
‚îî‚îÄ storeapi CPU: 65-80%

200 usuarios (posible degradaci√≥n):
‚îú‚îÄ Success rate: 85-90%
‚îú‚îÄ p95 latency: 1200-1800ms ‚ö†Ô∏è
‚îî‚îÄ storeapi CPU: 75-90% ‚ö†Ô∏è

250-300 usuarios (saturaci√≥n esperada):
‚îú‚îÄ Success rate: 70-85% ‚ö†Ô∏è
‚îú‚îÄ p95 latency: >2000ms ‚ö†Ô∏è
‚îú‚îÄ Posibles errores: 502/503/504
‚îî‚îÄ storeapi CPU: >90% ‚ö†Ô∏è
```

**Capacidad m√°xima estimada:** 150-200 usuarios concurrentes manteniendo SLO (p95 ‚â§ 1s)

**Cuellos de botella identificados:**
- CPU de storeapi (procesamiento de multipart uploads)
- Ancho de banda de red (subida de archivos grandes)
- Latencia de escritura en almacenamiento

#### Escenario 3: Sustained Test (10 minutos carga constante)

**Prop√≥sito:** Detectar degradaci√≥n progresiva y memory leaks

```text
Archivo: postman/results/report_sustained_TIMESTAMP.html

M√©tricas esperadas:
‚îú‚îÄ Total requests: 600-1200 (depende de RPS)
‚îú‚îÄ Success rate: 95-100% (debe mantenerse estable)
‚îú‚îÄ p95 latency: Variaci√≥n ‚â§ 10% durante toda la prueba
‚îî‚îÄ Duration: 10 minutos

Recursos (an√°lisis temporal):
‚îú‚îÄ CPU: Debe mantenerse estable (¬±5%)
‚îú‚îÄ Memory: Crecimiento ‚â§ 50 MB en 10 min (sin leaks)
‚îú‚îÄ Network I/O: Constante
‚îî‚îÄ No hay degradaci√≥n progresiva de latencia

Worker (worker_timing_TIMESTAMP.csv):
‚îú‚îÄ Tasks procesados: 100-200
‚îú‚îÄ Tiempo promedio estable durante toda la prueba
‚îú‚îÄ Cola de Kafka no crece indefinidamente
‚îî‚îÄ Worker mantiene throughput constante
```

**Se√±ales de alerta:**
- ‚ö†Ô∏è Latencia incrementa >20% en los √∫ltimos 5 minutos
- ‚ö†Ô∏è Memory crece >100 MB (posible leak)
- ‚ö†Ô∏è Error rate aumenta con el tiempo

#### Escenario 4: Stress Test (sobrecarga progresiva)

**Prop√≥sito:** Encontrar el punto de fallo y observar recuperaci√≥n

```text
Archivo: postman/results/report_stress_TIMESTAMP.html

Comportamiento esperado:

Fase 1 (0-5 min, carga normal):
‚îú‚îÄ Success rate: 95-100%
‚îî‚îÄ Sistema estable

Fase 2 (5-10 min, sobrecarga):
‚îú‚îÄ Success rate: 70-90% (degradaci√≥n aceptable)
‚îú‚îÄ p95 latency: 2-5s ‚ö†Ô∏è
‚îú‚îÄ Errores 502/503/504 comienzan a aparecer
‚îî‚îÄ CPU >95% sostenido

Fase 3 (10+ min, saturaci√≥n):
‚îú‚îÄ Success rate: 50-70% ‚ö†Ô∏è
‚îú‚îÄ Sistema no acepta nuevas conexiones
‚îú‚îÄ Posible crash de contenedores
‚îî‚îÄ Punto de quiebre identificado

Fase 4 (recuperaci√≥n, post-carga):
‚îú‚îÄ Sistema debe recuperarse en <2 minutos
‚îú‚îÄ Sin errores persistentes
‚îî‚îÄ M√©tricas vuelven a baseline
```

**Objetivos:**
- Identificar capacidad m√°xima absoluta
- Validar que el sistema no colapsa permanentemente
- Documentar comportamiento ante sobrecarga

#### Escenario 5: Spike Test (picos repentinos)

**Prop√≥sito:** Evaluar respuesta ante tr√°fico s√∫bito

```text
Archivo: postman/results/report_spike_TIMESTAMP.html

Patr√≥n esperado:

Baseline (1 min):
‚îú‚îÄ 10-20 usuarios
‚îî‚îÄ Sistema estable

Spike (30s):
‚îú‚îÄ 200-500 usuarios instant√°neos ‚ö†Ô∏è
‚îú‚îÄ Success rate: 60-80% (algunos timeouts esperados)
‚îú‚îÄ p95 latency: 3-10s ‚ö†Ô∏è
‚îî‚îÄ CPU spike: >90%

Recuperaci√≥n (2 min):
‚îú‚îÄ Sistema debe estabilizarse en <1 minuto
‚îú‚îÄ Success rate vuelve a >95%
‚îú‚îÄ Sin errores persistentes post-spike
‚îî‚îÄ CPU retorna a <50%
```

**M√©tricas clave:**
- Tiempo de recuperaci√≥n: ‚â§60 segundos
- Porcentaje de requests exitosos durante spike: ‚â•60%
- Sin crashes de contenedores

#### An√°lisis Comparativo de Worker

Para evaluar el rendimiento del worker con diferentes configuraciones:

```text
worker_timing_TIMESTAMP.csv consolidado:

Configuraci√≥n: 1 worker
‚îú‚îÄ Throughput: 3-5 videos/min
‚îú‚îÄ FFmpeg time avg: 10-14s (80% del tiempo total)
‚îú‚îÄ Cola de Kafka: Crece si RPS > 5/min
‚îî‚îÄ CPU: 70-90% sostenido

Configuraci√≥n: 2 workers (escalar con docker-compose)
‚îú‚îÄ Throughput: 6-10 videos/min (casi lineal)
‚îú‚îÄ FFmpeg time: Sin cambios (CPU-bound)
‚îú‚îÄ Cola de Kafka: Drena m√°s r√°pido
‚îî‚îÄ CPU por worker: 65-85%

Configuraci√≥n: 4 workers
‚îú‚îÄ Throughput: 10-18 videos/min (no lineal si hay contenci√≥n)
‚îú‚îÄ Posible contenci√≥n: DB, S3, IO
‚îî‚îÄ CPU total: Puede saturar host local
```

**Recomendaci√≥n:** 2 workers es el punto √≥ptimo para entorno local sin saturar recursos del host.

---

## 13. Riesgos y Limitaciones

### 13.1 Limitaciones del Entorno Local

- ‚ö†Ô∏è El hardware local puede diferir significativamente de un entorno productivo (CPU, IO, red)
- ‚ö†Ô∏è Docker Desktop en macOS/Windows introduce sobrecarga adicional comparado con Linux nativo
- ‚ö†Ô∏è Compartir recursos con otros procesos del sistema puede afectar resultados
- ‚ö†Ô∏è Almacenamiento local es m√°s r√°pido que S3 real (puede enmascarar latencias)

### 13.2 Riesgos Identificados

| Riesgo | Impacto | Mitigaci√≥n |
|--------|---------|------------|
| Hardware insuficiente causa fallos prematuros | Alto | Documentar specs y ajustar expectativas |
| Variabilidad entre ejecuciones por procesos background | Medio | Ejecutar 5+ iteraciones y promediar |
| Agotamiento de disco por videos acumulados | Medio | Limpiar `videos/` entre pruebas |
| Timeout de Kafka o DB por recursos | Alto | Monitorear logs y ajustar configuraciones |
| Newman no genera suficiente concurrencia | Medio | Ejecutar m√∫ltiples instancias en paralelo |

---

## 14. Referencia R√°pida de Comandos

### Setup Inicial

```bash
# 1. Levantar infraestructura
make -C ./capacity-planning/ up

# 2. Verificar estado
make -C ./capacity-planning/ ps

# 3. Ver logs
make -C ./capacity-planning/ logs
```

### Ejecuci√≥n de Tests

```bash
# Validaci√≥n b√°sica (5 usuarios, 1 min)
make -C ./capacity-planning/ test-smoke

# Encontrar capacidad m√°xima (50‚Üí300 usuarios)
make -C ./capacity-planning/ test-capacity

# Rampa gradual
make -C ./capacity-planning/ test-ramp

# Carga sostenida (10 min)
make -C ./capacity-planning/ test-sustained

# Prueba de estr√©s (hasta fallo)
make -C ./capacity-planning/ test-stress

# Picos repentinos
make -C ./capacity-planning/ test-spike
```

### Monitoreo Manual

```bash
# Iniciar monitores
make -C ./capacity-planning/ monitor-start

# ... realizar operaciones manuales ...

# Detener y calcular estad√≠sticas
make -C ./capacity-planning/ monitor-stop

# Forzar detenci√≥n si se cuelga
make -C ./capacity-planning/ kill-monitors
```

### An√°lisis de Resultados

```bash
# Ver estad√≠sticas en consola
make -C ./capacity-planning/ view-stats

# Calcular estad√≠sticas manualmente
make -C ./capacity-planning/ calculate-stats

# Abrir directorio de resultados
make -C ./capacity-planning/ show-results

# Abrir reporte en navegador (macOS)
open capacity-planning/postman/results/report_*.html
```

### Limpieza

```bash
# Detener servicios
make -C ./capacity-planning/ down

# Limpiar archivos temporales
make -C ./capacity-planning/ clean

# Ayuda
make -C ./capacity-planning/ help
```

### Archivos Generados

Todos los resultados se guardan en: `capacity-planning/postman/results/`

- **report_[test]_[timestamp].html**: Reporte HTML de Newman con m√©tricas HTTP
- **container_stats_[timestamp].csv**: M√©tricas de CPU, memoria, red, disco por contenedor
- **worker_timing_[timestamp].csv**: Tiempos de procesamiento por tarea (task_id, video_id, tiempos)
- **summary_[timestamp].csv**: Estad√≠sticas consolidadas (min, max, avg, median, p95)

### Workflow Completo Recomendado

```bash
# 1. Setup
make -C ./capacity-planning/ up
make -C ./capacity-planning/ ps

# 2. Smoke test (validaci√≥n)
make -C ./capacity-planning/ test-smoke

# 3. Capacity test (encontrar l√≠mites)
make -C ./capacity-planning/ test-capacity

# 4. Sustained test (estabilidad)
make -C ./capacity-planning/ test-sustained

# 5. Ver resultados
make -C ./capacity-planning/ view-stats
make -C ./capacity-planning/ show-results

# 6. Limpiar
make -C ./capacity-planning/ down
```

---

# Analisis de Resultados Finales

## Interpretaci√≥n de Resultados

- **p95 ‚â§ 1s** = Sistema cumple SLO ‚úÖ
- **Error rate ‚â§ 5%** = Disponibilidad aceptable ‚úÖ
- **CPU < 85%** = Margen para picos de tr√°fico ‚úÖ
- **Worker queue estable** = Throughput suficiente ‚úÖ

## Recomendaciones Post-An√°lisis

1. **Si p95 > 1s con <100 usuarios**: Optimizar c√≥digo de API (profiling, caching)
2. **Si CPU de storeapi >90%**: Escalar horizontalmente (m√°s instancias)
3. **Si worker queue crece**: Aumentar paralelismo de workers
4. **Si hay memory leaks**: Revisar gesti√≥n de recursos y conexiones
5. **Si errores 5xx frecuentes**: Revisar logs de aplicaci√≥n y dependencias

